{"cells":[{"cell_type":"markdown","source":["# ResNet 과제\n","## 1. 기본 코드(cifar10 dataset) 돌리면서 코드 파악\n","\n","## 2. 원하는 dataset 선택\n","- dataset에 따른 imgsize & class 개수 등 조절 필요\n","\n","## 3. Parameter 바꿔가면서 성능 변화 확인하기\n","  - image 크기(resize)\n","  - learning rate\n","  - optimizer\n","\n","<br/>\n","<br/>\n","\n","학습시간이 너무 오래 걸리면 epoch수를 줄이고, 다양한 시도를 해보면 좋을 것!!\n","\n","참고 데이터셋\n","- https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n","- 그 외 원하는 이미지 데이터셋 자유롭게 사용 가능"],"metadata":{"id":"JYWuOh6tva5L"}},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"G14yjsROmGxn"},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tensorflow\n","device_name = tensorflow.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"bFHrnvzLjgfW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81cc2586-d68a-481e-fc6c-32f631d44eed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"metadata":{"id":"47uahMnwmGxo"},"cell_type":"markdown","source":["## ResNet 구현\n","### 1. identity block을 생성하는 함수인 identity_block() 생성. \n","* input_tensor : 입력 tensor\n","\n","* kernel_size : kernel 크기\n","  - identity block 내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임 (3x3 커널이 아니라 5x5 kernel도 지정할 수 있게 구성)\n","* filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음\n","  * 첫번째 : 첫번째 1x1 filter 개수 (tensor의 channel 차원을 1/4로 축소)\n","  * 두번째 : 3x3 filter 개수\n","  * 세번째 : 마지막 1x1 filter 개수 (tensor의 차원 복구)\n","* stage: identity block들을 구별하기 위해서 설정 & 동일한 filter수를 가지는 identity block들은 동일한 stage로 설정\n","* block: 동일 stage내에서 identity block을 구별하기 위한 구분자 (a,b,c)\n","\n","![](https://raw.githubusercontent.com/chulminkw/CNN_PG/main/utils/images/residual_block_small.png)\n"]},{"metadata":{"trusted":true,"id":"Pdxw4_nVmGxp"},"cell_type":"code","source":["from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation\n","from tensorflow.keras.layers import add, Add\n","\n","# identity block은 shortcut 단에 conv layer가 없는 block 영역\n","def identity_block(input_tensor, middle_kernel_size, filters, stage, block):\n","    '''\n","    함수 입력 인자 설명\n","    input_tensor : 입력 tensor\n","\n","    middle_kernel_size : 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n","    (3x3 커널이 이외에도 5x5 kernel도 지정할 수 있게 구성)\n","\n","    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, 세번째는 마지막 1x1 filter 개수\n","\n","    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n","\n","    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n","    ''' \n","    \n","    # filters : filter 개수를 각각 filter1, filter2, filter3 list 형태로 할당. \n","    # filter은 첫번째 1x1 filter 개수\n","    # filter2는 3x3 filter 개수\n","    # filter3는 마지막 1x1 filter 개수\n","    filter1, filter2, filter3 = filters\n","    \n","    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정\n","    # 입력받은 stage와 block에 기반하여 이름 부여\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # 이전 layer에 입력 받은 input_tensor를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n","    # 첫번째 1x1 Conv에서 Channel Dimension Reduction(1/4) 수행\n","    x = Conv2D(filters=filter1, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n","    x = Activation('relu')(x)\n","    \n","    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n","    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용\n","    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정\n","    # filter 개수는 이전의 1x1 filter개수와 동일\n","    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n","    x = Activation('relu')(x)\n","    \n","    # 마지막 1x1 Conv->Batch Norm 수행\n","    # ReLU를 수행 X (input tensor 더한 이후에 ReLU 적용)\n","    # filter 크기는 input_tensor channel 차원 개수로 복구\n","    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n","\n","    # Residual Block 수행 결과 & input_tensor를 합 (Skip Connection)\n","    x = Add()([input_tensor, x])\n","\n","    # 최종 ReLU 적용\n","    x = Activation('relu')(x)\n","    \n","    return x"],"execution_count":null,"outputs":[]},{"metadata":{"id":"mnPHdMIImGxq"},"cell_type":"markdown","source":["### 2. 위에서 생성한 identity_block()을 호출하여 어떻게 identity block이 구성되어 있는지 확인"]},{"metadata":{"trusted":true,"id":"j-V8Yqy1mGxq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4808b4b1-d87d-4f5c-dcd1-b6fff79f917f"},"cell_type":"code","source":["from tensorflow.keras.layers import Input\n","from tensorflow.keras.models import Model\n","\n","# input_tensor로 임의의 Feature Map size를 생성. \n","input_tensor = Input(shape=(56, 56, 256), name='test_input')\n","\n","# input_tensor의 channel수는 256개\n","# filters는 256의 1/4 filter수로 차원 축소후 다시 마지막 1x1 Conv에서 256으로 복원\n","filters = [64, 64, 256]\n","\n","# 중간 Conv 커널 크기 : 3x3\n","kernel_size = (3, 3)\n","stage = 2\n","block = 'a'\n","\n","# identity_block 호출 & layer들이 어떻게 구성되어 있는지 확인하기 위해서 model로 구성하고 summary()호출 \n","output = identity_block(input_tensor, kernel_size, filters, stage, block)\n","identity_layers = Model(inputs=input_tensor, outputs=output)\n","identity_layers.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['test_input[0][0]']             \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation (Activation)        (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation[0][0]']             \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_1 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_1[0][0]']           \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add (Add)                      (None, 56, 56, 256)  0           ['test_input[0][0]',             \n","                                                                  'bn2a_branch2c[0][0]']          \n","                                                                                                  \n"," activation_2 (Activation)      (None, 56, 56, 256)  0           ['add[0][0]']                    \n","                                                                                                  \n","==================================================================================================\n","Total params: 71,552\n","Trainable params: 70,784\n","Non-trainable params: 768\n","__________________________________________________________________________________________________\n"]}]},{"metadata":{"id":"DwwWqDhGmGxq"},"cell_type":"markdown","source":["### 3. identity block을 연속으로 이어서 하나의 Stage 구성.\n","* 아래는 input tensor의 크기가 feature map 생성시 절반으로 줄지 않음\n","* input tensor의 크기가 절반으로 줄수 있도록 구성\n","* 동일한 Stage 내에서 feature map의 크기는 그대로 & block내에서 filter 개수는 변화"]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"qoavj1qVmGxr","outputId":"b80c53dc-7475-48c3-9e17-d116d669433a"},"cell_type":"code","source":["input_tensor = Input(shape=(56, 56, 256), name='test_input')\n","\n","x = identity_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='a')\n","x = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\n","\n","output = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\n","\n","identity_layers = Model(inputs=input_tensor, outputs=output)\n","identity_layers.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['test_input[0][0]']             \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_3 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_3[0][0]']           \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_4 (Activation)      (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_4[0][0]']           \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_1 (Add)                    (None, 56, 56, 256)  0           ['test_input[0][0]',             \n","                                                                  'bn2a_branch2c[0][0]']          \n","                                                                                                  \n"," activation_5 (Activation)      (None, 56, 56, 256)  0           ['add_1[0][0]']                  \n","                                                                                                  \n"," res2b_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_5[0][0]']           \n","                                                                                                  \n"," bn2b_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_6 (Activation)      (None, 56, 56, 64)   0           ['bn2b_branch2a[0][0]']          \n","                                                                                                  \n"," res2b_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_6[0][0]']           \n","                                                                                                  \n"," bn2b_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_7 (Activation)      (None, 56, 56, 64)   0           ['bn2b_branch2b[0][0]']          \n","                                                                                                  \n"," res2b_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_7[0][0]']           \n","                                                                                                  \n"," bn2b_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_2 (Add)                    (None, 56, 56, 256)  0           ['activation_5[0][0]',           \n","                                                                  'bn2b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_8 (Activation)      (None, 56, 56, 256)  0           ['add_2[0][0]']                  \n","                                                                                                  \n"," res2c_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_8[0][0]']           \n","                                                                                                  \n"," bn2c_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_9 (Activation)      (None, 56, 56, 64)   0           ['bn2c_branch2a[0][0]']          \n","                                                                                                  \n"," res2c_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_9[0][0]']           \n","                                                                                                  \n"," bn2c_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_10 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2b[0][0]']          \n","                                                                                                  \n"," res2c_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_10[0][0]']          \n","                                                                                                  \n"," bn2c_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_3 (Add)                    (None, 56, 56, 256)  0           ['activation_8[0][0]',           \n","                                                                  'bn2c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_11 (Activation)     (None, 56, 56, 256)  0           ['add_3[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 214,656\n","Trainable params: 212,352\n","Non-trainable params: 2,304\n","__________________________________________________________________________________________________\n"]}]},{"metadata":{"id":"fBGZg0qFmGxr"},"cell_type":"markdown","source":["### 4. 각 stage내의 첫번째 identity block에서 입력 feature map의 크기를 절반으로 줄이는 conv_block() 만들기\n","* conv_block() 함수는 앞에서 구현한 identity_block()함수과 거의 유사\n","* 입력 feature map의 크기를 절반으로 줄이고 shortcut 전달시 1x1 conv & stride 2 적용\n","* 첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않음"]},{"metadata":{"trusted":true,"id":"TKuxKe_TmGxs"},"cell_type":"code","source":["def conv_block(input_tensor, middle_kernel_size, filters, stage, block, strides=(2, 2)):\n","    '''\n","    함수 입력 인자 설명\n","    input_tensor: 입력 tensor\n","\n","    middle_kernel_size: 중간에 위치하는 kernel 크기. identity block내에 있는 두개의 conv layer중 1x1 kernel이 아니고, 3x3 kernel임. \n","                        3x3 커널 이외에도 5x5 kernel도 지정할 수 있게 구성. \n","\n","    filters: 3개 conv layer들의 filter개수를 list 형태로 입력 받음. 첫번째 원소는 첫번째 1x1 filter 개수, 두번째는 3x3 filter 개수, \n","             세번째는 마지막 1x1 filter 개수\n","\n","    stage: identity block들이 여러개가 결합되므로 이를 구분하기 위해서 설정. 동일한 filter수를 가지는 identity block들을  동일한 stage로 설정.  \n","\n","    block: 동일 stage내에서 identity block을 구별하기 위한 구분자\n","\n","    strides: 입력 feature map의 크기를 절반으로 줄이기 위해서 사용. Default는 2이지만, \n","             첫번째 Stage의 첫번째 block에서는 이미 입력 feature map이 max pool로 절반이 줄어있는 상태이므로 다시 줄이지 않기 위해 1을 호출해야함 \n","    ''' \n","    \n","    # filters : filter 개수를 각각 filter1, filter2, filter3 list 형태로 할당. \n","    # filter은 첫번째 1x1 filter 개수\n","    # filter2는 3x3 filter 개수\n","    # filter3는 마지막 1x1 filter 개수\n","    filter1, filter2, filter3 = filters\n","\n","    # conv layer와 Batch normalization layer각각에 고유한 이름을 부여하기 위해 설정. 입력받은 stage와 block에 기반하여 이름 부여\n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    \n","    # 이전 layer에 입력 받은 input_tensor를 기반으로 첫번째 1x1 Conv->Batch Norm->Relu 수행. \n","    # 입력 feature map 사이즈를 1/2로 줄이기 위해 strides 입력  \n","    x = Conv2D(filters=filter1, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'2a')(input_tensor)\n","    \n","    # Batch Norm 적용\n","    # 입력 데이터는 batch 사이즈까지 포함하여 4차원 : (batch_size, height, width, channel depth)\n","    # Batch Norm의 axis는 channel depth에 해당하는 axis index인 3을 입력 (무조건 channel이 마지막 차원의 값으로 입력된다고 가정)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2a')(x)\n","    # ReLU Activation 적용\n","    x = Activation('relu')(x)\n","    \n","    # 두번째 3x3 Conv->Batch Norm->ReLU 수행\n","    # 3x3이 아닌 다른 kernel size도 구성 가능할 수 있도록 identity_block() 인자로 입력받은 middle_kernel_size를 이용. \n","    # Conv 수행 출력 사이즈가 변하지 않도록 padding='same'으로 설정. filter 개수는 이전의 1x1 filter개수와 동일.  \n","    x = Conv2D(filters=filter2, kernel_size=middle_kernel_size, padding='same', kernel_initializer='he_normal', name=conv_name_base+'2b')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2b')(x)\n","    x = Activation('relu')(x)\n","    \n","    # 마지막 1x1 Conv->Batch Norm 수행\n","    # ReLU를 수행 X (input tensor 더한 이후에 ReLU 적용)\n","    # filter 크기는 input_tensor channel 차원 개수로 복구\n","    x = Conv2D(filters=filter3, kernel_size=(1, 1), kernel_initializer='he_normal', name=conv_name_base+'2c')(x)\n","    x = BatchNormalization(axis=3, name=bn_name_base+'2c')(x)\n","    \n","    # shortcut을 1x1 conv 수행, filter3가 입력 feature map의 filter 개수\n","    shortcut = Conv2D(filter3, (1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base+'1')(input_tensor)\n","    shortcut = BatchNormalization(axis=3, name=bn_name_base+'1')(shortcut)\n","    \n","    # Residual Block 수행 결과 & 1x1 conv가 적용된 shortcut을 합 \n","    x = add([x, shortcut])\n","    \n","    # 최종 ReLU 적용\n","    x = Activation('relu')(x)\n","    \n","    return x\n","    "],"execution_count":null,"outputs":[]},{"metadata":{"id":"PePSmhJ9mGxs"},"cell_type":"markdown","source":["### 5. conv_block()과 identity_block()을 호출하여 stage 구성."]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"w0znd7clmGxs","outputId":"65ae6af4-77d2-493e-a5a2-48719538881e"},"cell_type":"code","source":["input_tensor = Input(shape=(56, 56, 256), name='test_input')\n","\n","# conv_block() 호출 시 strides를 2로 설정하여 입력 feature map의 크기를 절반으로 줄임 / strides=1이면 크기를 그대로 유지\n","x = conv_block(input_tensor, middle_kernel_size=3, filters=[64, 64, 256], strides=2, stage=2, block='a')\n","x = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='b')\n","\n","output = identity_block(x, middle_kernel_size=3, filters=[64, 64, 256], stage=2, block='c')\n","\n","identity_layers = Model(inputs=input_tensor, outputs=output)\n","identity_layers.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," test_input (InputLayer)        [(None, 56, 56, 256  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['test_input[0][0]']             \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_12 (Activation)     (None, 28, 28, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_12[0][0]']          \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_13 (Activation)     (None, 28, 28, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_13[0][0]']          \n","                                                                                                  \n"," res2a_branch1 (Conv2D)         (None, 28, 28, 256)  65792       ['test_input[0][0]']             \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn2a_branch1 (BatchNormalizati  (None, 28, 28, 256)  1024       ['res2a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_4 (Add)                    (None, 28, 28, 256)  0           ['bn2a_branch2c[0][0]',          \n","                                                                  'bn2a_branch1[0][0]']           \n","                                                                                                  \n"," activation_14 (Activation)     (None, 28, 28, 256)  0           ['add_4[0][0]']                  \n","                                                                                                  \n"," res2b_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['activation_14[0][0]']          \n","                                                                                                  \n"," bn2b_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_15 (Activation)     (None, 28, 28, 64)   0           ['bn2b_branch2a[0][0]']          \n","                                                                                                  \n"," res2b_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_15[0][0]']          \n","                                                                                                  \n"," bn2b_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_16 (Activation)     (None, 28, 28, 64)   0           ['bn2b_branch2b[0][0]']          \n","                                                                                                  \n"," res2b_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_16[0][0]']          \n","                                                                                                  \n"," bn2b_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_5 (Add)                    (None, 28, 28, 256)  0           ['activation_14[0][0]',          \n","                                                                  'bn2b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_17 (Activation)     (None, 28, 28, 256)  0           ['add_5[0][0]']                  \n","                                                                                                  \n"," res2c_branch2a (Conv2D)        (None, 28, 28, 64)   16448       ['activation_17[0][0]']          \n","                                                                                                  \n"," bn2c_branch2a (BatchNormalizat  (None, 28, 28, 64)  256         ['res2c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_18 (Activation)     (None, 28, 28, 64)   0           ['bn2c_branch2a[0][0]']          \n","                                                                                                  \n"," res2c_branch2b (Conv2D)        (None, 28, 28, 64)   36928       ['activation_18[0][0]']          \n","                                                                                                  \n"," bn2c_branch2b (BatchNormalizat  (None, 28, 28, 64)  256         ['res2c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_19 (Activation)     (None, 28, 28, 64)   0           ['bn2c_branch2b[0][0]']          \n","                                                                                                  \n"," res2c_branch2c (Conv2D)        (None, 28, 28, 256)  16640       ['activation_19[0][0]']          \n","                                                                                                  \n"," bn2c_branch2c (BatchNormalizat  (None, 28, 28, 256)  1024       ['res2c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_6 (Add)                    (None, 28, 28, 256)  0           ['activation_17[0][0]',          \n","                                                                  'bn2c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_20 (Activation)     (None, 28, 28, 256)  0           ['add_6[0][0]']                  \n","                                                                                                  \n","==================================================================================================\n","Total params: 281,472\n","Trainable params: 278,656\n","Non-trainable params: 2,816\n","__________________________________________________________________________________________________\n"]}]},{"metadata":{"id":"HG40II7lmGxs"},"cell_type":"markdown","source":["### 6. input image를 7x7 Conv 변환하고 Max Pooling 적용 로직을 별도 함수로 구현.\n","* O = (I - F + 2P)/S + 1, I는 Input size, F는 filter의 kernel 크기, P는 padding, S는 Stride\n","* (224 - 7)/2 + 1 = 109.5 = 109가 됨. 따라서 112x112 로 출력하기 위해 ZeroPadding2D(3, 3)수행\n","* 112x112로 MaxPooling 을 (3, 3) pool size로 stride 2로 수행하므로 56x56으로 출력하기 위해 ZeroPadding2D(1,1) 수행"]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"LC4yuaf9mGxs","outputId":"4744ceaa-b8c1-4de2-cb18-36c85494b7a3"},"cell_type":"code","source":["from tensorflow.keras.layers import ZeroPadding2D, MaxPooling2D\n","\n","def do_first_conv(input_tensor):\n","    # 7x7 Conv 연산 수행하여 feature map 생성, input_tensor 크기를 절반으로 생성\n","    # filter 개수 : 64개 \n","    # 224x224 를 input -> 7x7 conv, strides=2 -> 112x112 출력 (Zero padding 적용)\n","    x = ZeroPadding2D(padding=(3, 3), name='conv1_pad')(input_tensor)\n","    x = Conv2D(64, (7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal', name='conv')(x)\n","    x = BatchNormalization(axis=3, name='bn_conv1')(x)\n","    x = Activation('relu')(x)\n","\n","    # 다시 feature map 크기를 MaxPooling으로 절반으로 만듬 -> 56x56으로 출력 (zero padding 적용)\n","    x = ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n","    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n","    \n","    return x\n","\n","input_tensor = Input(shape=(224, 224, 3))\n","output = do_first_conv(input_tensor)\n","model = Model(inputs=input_tensor, outputs=output)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)       0         \n","                                                                 \n"," conv (Conv2D)               (None, 112, 112, 64)      9472      \n","                                                                 \n"," bn_conv1 (BatchNormalizatio  (None, 112, 112, 64)     256       \n"," n)                                                              \n","                                                                 \n"," activation_21 (Activation)  (None, 112, 112, 64)      0         \n","                                                                 \n"," pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)      0         \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 56, 56, 64)       0         \n"," )                                                               \n","                                                                 \n","=================================================================\n","Total params: 9,728\n","Trainable params: 9,600\n","Non-trainable params: 128\n","_________________________________________________________________\n"]}]},{"metadata":{"id":"BIPGKFf8mGxt"},"cell_type":"markdown","source":["### 7. ResNet 50 모델 생성.\n","* 앞에서 생성한 conv_block()과 identity_block()을 호출하여 ResNet 50 모델 생성. "]},{"metadata":{"trusted":true,"id":"pfGN0j-7mGxt"},"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","def create_resnet(in_shape=(224, 224, 3), n_classes=10):\n","    input_tensor = Input(shape=in_shape)\n","    \n","    # 첫번째 7x7 Conv와 Max Pooling 적용.  \n","    x = do_first_conv(input_tensor)\n","    \n","    # stage 2의 conv_block과 identity block 생성\n","    # stage2의 첫번째 conv_block은 strides를 1로 하여 크기를 줄이지 않음. \n","    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n","    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n","    \n","    # stage 3의 conv_block과 identity block 생성\n","    # stage3의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임 \n","    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n","    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n","\n","    # stage 4의 conv_block과 identity block 생성\n","    # stage4의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n","    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n","    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    # stage 5의 conv_block과 identity block 생성\n","    # stage5의 첫번째 conv_block은 strides를 2(default)로 하여 크기를 줄임\n","    x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n","    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n","    \n","    # classification dense layer와 연결 전 GlobalAveragePooling 수행 \n","    x = GlobalAveragePooling2D(name='avg_pool')(x)\n","    x = Dropout(rate=0.5)(x)\n","    x = Dense(200, activation='relu', name='fc_01')(x)\n","    x = Dropout(rate=0.5)(x)\n","   \n","    # 마지막 fully connected layer & Softmax 함수를 이용해 확률 반환\n","    output = Dense(n_classes, activation='softmax', name='fc_final')(x) \n","    \n","    # model 구성\n","    model = Model(inputs=input_tensor, outputs=output, name='resnet50')\n","    model.summary()\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"UldtROIAmGxt","outputId":"b3bc1790-bbe4-458a-997d-16b2920a44dd"},"cell_type":"code","source":["model =  create_resnet(in_shape=(224,224,3), n_classes=10)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n","                                                                                                  \n"," conv (Conv2D)                  (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," bn_conv1 (BatchNormalization)  (None, 112, 112, 64  256         ['conv[0][0]']                   \n","                                )                                                                 \n","                                                                                                  \n"," activation_22 (Activation)     (None, 112, 112, 64  0           ['bn_conv1[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['activation_22[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)  0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 56, 56, 64)   4160        ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_23 (Activation)     (None, 56, 56, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_23[0][0]']          \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_24 (Activation)     (None, 56, 56, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_24[0][0]']          \n","                                                                                                  \n"," res2a_branch1 (Conv2D)         (None, 56, 56, 256)  16640       ['max_pooling2d_1[0][0]']        \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn2a_branch1 (BatchNormalizati  (None, 56, 56, 256)  1024       ['res2a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_7 (Add)                    (None, 56, 56, 256)  0           ['bn2a_branch2c[0][0]',          \n","                                                                  'bn2a_branch1[0][0]']           \n","                                                                                                  \n"," activation_25 (Activation)     (None, 56, 56, 256)  0           ['add_7[0][0]']                  \n","                                                                                                  \n"," res2b_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_25[0][0]']          \n","                                                                                                  \n"," bn2b_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_26 (Activation)     (None, 56, 56, 64)   0           ['bn2b_branch2a[0][0]']          \n","                                                                                                  \n"," res2b_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_26[0][0]']          \n","                                                                                                  \n"," bn2b_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_27 (Activation)     (None, 56, 56, 64)   0           ['bn2b_branch2b[0][0]']          \n","                                                                                                  \n"," res2b_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_27[0][0]']          \n","                                                                                                  \n"," bn2b_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_8 (Add)                    (None, 56, 56, 256)  0           ['activation_25[0][0]',          \n","                                                                  'bn2b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_28 (Activation)     (None, 56, 56, 256)  0           ['add_8[0][0]']                  \n","                                                                                                  \n"," res2c_branch2a (Conv2D)        (None, 56, 56, 64)   16448       ['activation_28[0][0]']          \n","                                                                                                  \n"," bn2c_branch2a (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_29 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2a[0][0]']          \n","                                                                                                  \n"," res2c_branch2b (Conv2D)        (None, 56, 56, 64)   36928       ['activation_29[0][0]']          \n","                                                                                                  \n"," bn2c_branch2b (BatchNormalizat  (None, 56, 56, 64)  256         ['res2c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_30 (Activation)     (None, 56, 56, 64)   0           ['bn2c_branch2b[0][0]']          \n","                                                                                                  \n"," res2c_branch2c (Conv2D)        (None, 56, 56, 256)  16640       ['activation_30[0][0]']          \n","                                                                                                  \n"," bn2c_branch2c (BatchNormalizat  (None, 56, 56, 256)  1024       ['res2c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_9 (Add)                    (None, 56, 56, 256)  0           ['activation_28[0][0]',          \n","                                                                  'bn2c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_31 (Activation)     (None, 56, 56, 256)  0           ['add_9[0][0]']                  \n","                                                                                                  \n"," res3a_branch2a (Conv2D)        (None, 28, 28, 128)  32896       ['activation_31[0][0]']          \n","                                                                                                  \n"," bn3a_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_32 (Activation)     (None, 28, 28, 128)  0           ['bn3a_branch2a[0][0]']          \n","                                                                                                  \n"," res3a_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_32[0][0]']          \n","                                                                                                  \n"," bn3a_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_33 (Activation)     (None, 28, 28, 128)  0           ['bn3a_branch2b[0][0]']          \n","                                                                                                  \n"," res3a_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_33[0][0]']          \n","                                                                                                  \n"," res3a_branch1 (Conv2D)         (None, 28, 28, 512)  131584      ['activation_31[0][0]']          \n","                                                                                                  \n"," bn3a_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn3a_branch1 (BatchNormalizati  (None, 28, 28, 512)  2048       ['res3a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_10 (Add)                   (None, 28, 28, 512)  0           ['bn3a_branch2c[0][0]',          \n","                                                                  'bn3a_branch1[0][0]']           \n","                                                                                                  \n"," activation_34 (Activation)     (None, 28, 28, 512)  0           ['add_10[0][0]']                 \n","                                                                                                  \n"," res3b_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_34[0][0]']          \n","                                                                                                  \n"," bn3b_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_35 (Activation)     (None, 28, 28, 128)  0           ['bn3b_branch2a[0][0]']          \n","                                                                                                  \n"," res3b_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_35[0][0]']          \n","                                                                                                  \n"," bn3b_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_36 (Activation)     (None, 28, 28, 128)  0           ['bn3b_branch2b[0][0]']          \n","                                                                                                  \n"," res3b_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_36[0][0]']          \n","                                                                                                  \n"," bn3b_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_11 (Add)                   (None, 28, 28, 512)  0           ['activation_34[0][0]',          \n","                                                                  'bn3b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_37 (Activation)     (None, 28, 28, 512)  0           ['add_11[0][0]']                 \n","                                                                                                  \n"," res3c_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_37[0][0]']          \n","                                                                                                  \n"," bn3c_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_38 (Activation)     (None, 28, 28, 128)  0           ['bn3c_branch2a[0][0]']          \n","                                                                                                  \n"," res3c_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_38[0][0]']          \n","                                                                                                  \n"," bn3c_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_39 (Activation)     (None, 28, 28, 128)  0           ['bn3c_branch2b[0][0]']          \n","                                                                                                  \n"," res3c_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_39[0][0]']          \n","                                                                                                  \n"," bn3c_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_12 (Add)                   (None, 28, 28, 512)  0           ['activation_37[0][0]',          \n","                                                                  'bn3c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_40 (Activation)     (None, 28, 28, 512)  0           ['add_12[0][0]']                 \n","                                                                                                  \n"," res3d_branch2a (Conv2D)        (None, 28, 28, 128)  65664       ['activation_40[0][0]']          \n","                                                                                                  \n"," bn3d_branch2a (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_41 (Activation)     (None, 28, 28, 128)  0           ['bn3d_branch2a[0][0]']          \n","                                                                                                  \n"," res3d_branch2b (Conv2D)        (None, 28, 28, 128)  147584      ['activation_41[0][0]']          \n","                                                                                                  \n"," bn3d_branch2b (BatchNormalizat  (None, 28, 28, 128)  512        ['res3d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_42 (Activation)     (None, 28, 28, 128)  0           ['bn3d_branch2b[0][0]']          \n","                                                                                                  \n"," res3d_branch2c (Conv2D)        (None, 28, 28, 512)  66048       ['activation_42[0][0]']          \n","                                                                                                  \n"," bn3d_branch2c (BatchNormalizat  (None, 28, 28, 512)  2048       ['res3d_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_13 (Add)                   (None, 28, 28, 512)  0           ['activation_40[0][0]',          \n","                                                                  'bn3d_branch2c[0][0]']          \n","                                                                                                  \n"," activation_43 (Activation)     (None, 28, 28, 512)  0           ['add_13[0][0]']                 \n","                                                                                                  \n"," res4a_branch2a (Conv2D)        (None, 14, 14, 256)  131328      ['activation_43[0][0]']          \n","                                                                                                  \n"," bn4a_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_44 (Activation)     (None, 14, 14, 256)  0           ['bn4a_branch2a[0][0]']          \n","                                                                                                  \n"," res4a_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_44[0][0]']          \n","                                                                                                  \n"," bn4a_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_45 (Activation)     (None, 14, 14, 256)  0           ['bn4a_branch2b[0][0]']          \n","                                                                                                  \n"," res4a_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_45[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," res4a_branch1 (Conv2D)         (None, 14, 14, 1024  525312      ['activation_43[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4a_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4a_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," bn4a_branch1 (BatchNormalizati  (None, 14, 14, 1024  4096       ['res4a_branch1[0][0]']          \n"," on)                            )                                                                 \n","                                                                                                  \n"," add_14 (Add)                   (None, 14, 14, 1024  0           ['bn4a_branch2c[0][0]',          \n","                                )                                 'bn4a_branch1[0][0]']           \n","                                                                                                  \n"," activation_46 (Activation)     (None, 14, 14, 1024  0           ['add_14[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4b_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_46[0][0]']          \n","                                                                                                  \n"," bn4b_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_47 (Activation)     (None, 14, 14, 256)  0           ['bn4b_branch2a[0][0]']          \n","                                                                                                  \n"," res4b_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_47[0][0]']          \n","                                                                                                  \n"," bn4b_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_48 (Activation)     (None, 14, 14, 256)  0           ['bn4b_branch2b[0][0]']          \n","                                                                                                  \n"," res4b_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_48[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4b_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4b_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_15 (Add)                   (None, 14, 14, 1024  0           ['activation_46[0][0]',          \n","                                )                                 'bn4b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_49 (Activation)     (None, 14, 14, 1024  0           ['add_15[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4c_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_49[0][0]']          \n","                                                                                                  \n"," bn4c_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_50 (Activation)     (None, 14, 14, 256)  0           ['bn4c_branch2a[0][0]']          \n","                                                                                                  \n"," res4c_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_50[0][0]']          \n","                                                                                                  \n"," bn4c_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_51 (Activation)     (None, 14, 14, 256)  0           ['bn4c_branch2b[0][0]']          \n","                                                                                                  \n"," res4c_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_51[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4c_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4c_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_16 (Add)                   (None, 14, 14, 1024  0           ['activation_49[0][0]',          \n","                                )                                 'bn4c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_52 (Activation)     (None, 14, 14, 1024  0           ['add_16[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4d_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_52[0][0]']          \n","                                                                                                  \n"," bn4d_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_53 (Activation)     (None, 14, 14, 256)  0           ['bn4d_branch2a[0][0]']          \n","                                                                                                  \n"," res4d_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_53[0][0]']          \n","                                                                                                  \n"," bn4d_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_54 (Activation)     (None, 14, 14, 256)  0           ['bn4d_branch2b[0][0]']          \n","                                                                                                  \n"," res4d_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_54[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4d_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4d_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_17 (Add)                   (None, 14, 14, 1024  0           ['activation_52[0][0]',          \n","                                )                                 'bn4d_branch2c[0][0]']          \n","                                                                                                  \n"," activation_55 (Activation)     (None, 14, 14, 1024  0           ['add_17[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4e_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_55[0][0]']          \n","                                                                                                  \n"," bn4e_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_56 (Activation)     (None, 14, 14, 256)  0           ['bn4e_branch2a[0][0]']          \n","                                                                                                  \n"," res4e_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_56[0][0]']          \n","                                                                                                  \n"," bn4e_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4e_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_57 (Activation)     (None, 14, 14, 256)  0           ['bn4e_branch2b[0][0]']          \n","                                                                                                  \n"," res4e_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_57[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4e_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4e_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_18 (Add)                   (None, 14, 14, 1024  0           ['activation_55[0][0]',          \n","                                )                                 'bn4e_branch2c[0][0]']          \n","                                                                                                  \n"," activation_58 (Activation)     (None, 14, 14, 1024  0           ['add_18[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res4f_branch2a (Conv2D)        (None, 14, 14, 256)  262400      ['activation_58[0][0]']          \n","                                                                                                  \n"," bn4f_branch2a (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_59 (Activation)     (None, 14, 14, 256)  0           ['bn4f_branch2a[0][0]']          \n","                                                                                                  \n"," res4f_branch2b (Conv2D)        (None, 14, 14, 256)  590080      ['activation_59[0][0]']          \n","                                                                                                  \n"," bn4f_branch2b (BatchNormalizat  (None, 14, 14, 256)  1024       ['res4f_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_60 (Activation)     (None, 14, 14, 256)  0           ['bn4f_branch2b[0][0]']          \n","                                                                                                  \n"," res4f_branch2c (Conv2D)        (None, 14, 14, 1024  263168      ['activation_60[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," bn4f_branch2c (BatchNormalizat  (None, 14, 14, 1024  4096       ['res4f_branch2c[0][0]']         \n"," ion)                           )                                                                 \n","                                                                                                  \n"," add_19 (Add)                   (None, 14, 14, 1024  0           ['activation_58[0][0]',          \n","                                )                                 'bn4f_branch2c[0][0]']          \n","                                                                                                  \n"," activation_61 (Activation)     (None, 14, 14, 1024  0           ['add_19[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," res5a_branch2a (Conv2D)        (None, 7, 7, 512)    524800      ['activation_61[0][0]']          \n","                                                                                                  \n"," bn5a_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_62 (Activation)     (None, 7, 7, 512)    0           ['bn5a_branch2a[0][0]']          \n","                                                                                                  \n"," res5a_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_62[0][0]']          \n","                                                                                                  \n"," bn5a_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_63 (Activation)     (None, 7, 7, 512)    0           ['bn5a_branch2b[0][0]']          \n","                                                                                                  \n"," res5a_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_63[0][0]']          \n","                                                                                                  \n"," res5a_branch1 (Conv2D)         (None, 7, 7, 2048)   2099200     ['activation_61[0][0]']          \n","                                                                                                  \n"," bn5a_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn5a_branch1 (BatchNormalizati  (None, 7, 7, 2048)  8192        ['res5a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_20 (Add)                   (None, 7, 7, 2048)   0           ['bn5a_branch2c[0][0]',          \n","                                                                  'bn5a_branch1[0][0]']           \n","                                                                                                  \n"," activation_64 (Activation)     (None, 7, 7, 2048)   0           ['add_20[0][0]']                 \n","                                                                                                  \n"," res5b_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_64[0][0]']          \n","                                                                                                  \n"," bn5b_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_65 (Activation)     (None, 7, 7, 512)    0           ['bn5b_branch2a[0][0]']          \n","                                                                                                  \n"," res5b_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_65[0][0]']          \n","                                                                                                  \n"," bn5b_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_66 (Activation)     (None, 7, 7, 512)    0           ['bn5b_branch2b[0][0]']          \n","                                                                                                  \n"," res5b_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_66[0][0]']          \n","                                                                                                  \n"," bn5b_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_21 (Add)                   (None, 7, 7, 2048)   0           ['activation_64[0][0]',          \n","                                                                  'bn5b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_67 (Activation)     (None, 7, 7, 2048)   0           ['add_21[0][0]']                 \n","                                                                                                  \n"," res5c_branch2a (Conv2D)        (None, 7, 7, 512)    1049088     ['activation_67[0][0]']          \n","                                                                                                  \n"," bn5c_branch2a (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_68 (Activation)     (None, 7, 7, 512)    0           ['bn5c_branch2a[0][0]']          \n","                                                                                                  \n"," res5c_branch2b (Conv2D)        (None, 7, 7, 512)    2359808     ['activation_68[0][0]']          \n","                                                                                                  \n"," bn5c_branch2b (BatchNormalizat  (None, 7, 7, 512)   2048        ['res5c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_69 (Activation)     (None, 7, 7, 512)    0           ['bn5c_branch2b[0][0]']          \n","                                                                                                  \n"," res5c_branch2c (Conv2D)        (None, 7, 7, 2048)   1050624     ['activation_69[0][0]']          \n","                                                                                                  \n"," bn5c_branch2c (BatchNormalizat  (None, 7, 7, 2048)  8192        ['res5c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_22 (Add)                   (None, 7, 7, 2048)   0           ['activation_67[0][0]',          \n","                                                                  'bn5c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_70 (Activation)     (None, 7, 7, 2048)   0           ['add_22[0][0]']                 \n","                                                                                                  \n"," avg_pool (GlobalAveragePooling  (None, 2048)        0           ['activation_70[0][0]']          \n"," 2D)                                                                                              \n","                                                                                                  \n"," dropout (Dropout)              (None, 2048)         0           ['avg_pool[0][0]']               \n","                                                                                                  \n"," fc_01 (Dense)                  (None, 200)          409800      ['dropout[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n","                                                                                                  \n"," fc_final (Dense)               (None, 10)           2010        ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 23,999,522\n","Trainable params: 23,946,402\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"]}]},{"metadata":{"id":"9QYNl6apmGxt"},"cell_type":"markdown","source":["## CIFAR10 데이터 세트로 ResNet 모델 학습 및 성능 테스트"]},{"metadata":{"trusted":true,"id":"1TjsWZQMmGxt"},"cell_type":"code","source":["IMAGE_SIZE = 128\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"metadata":{"id":"vtG_X3h7mGxt"},"cell_type":"markdown","source":["### 데이터 전처리/인코딩/스케일링 함수 및 CIFAR_Dataset 선언"]},{"metadata":{"trusted":true,"id":"-8Sym9UMmGxu"},"cell_type":"code","source":["import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar100\n","from tensorflow.keras.utils import Sequence\n","import cv2\n","import sklearn\n","\n","def zero_one_scaler(image):\n","    return image/255.0\n","\n","# One Hot Encoding(OHE)\n","def get_preprocessed_ohe(images, labels, pre_func=None):\n","    # preprocessing 함수가 입력되면 이를 이용하여 image array를 scaling 적용.\n","    if pre_func is not None:\n","        images = pre_func(images)\n","    # OHE 적용    \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=42):\n","\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경\n","    # Label에 대해서는 OHE 적용\n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","    \n","    # train valid split\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels )\n","\n","from tensorflow.keras.utils import Sequence\n","import cv2\n","import sklearn\n","\n","# 입력 인자 images_array labels는 모두 numpy array로 들어옴 (images_array는 32x32)\n","class CIFAR_Dataset(Sequence):\n","    def __init__(self, images_array, labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=None):\n","        '''\n","        파라미터 설명\n","\n","        images_array : 원본 32x32 만큼의 image 배열값. \n","\n","        labels : 해당 image의 label\n","\n","        batch_size : __getitem__(self, index) 호출 시 마다 가져올 데이터 batch 건수\n","\n","        augmentor : albumentations 객체\n","\n","        shuffle : 학습 데이터의 경우 epoch 종료시마다 데이터를 섞을지 여부\n","        '''\n","        # 객체 생성 인자로 들어온 값을 객체 내부 변수로 할당. \n","        # 인자로 입력되는 images_array는 전체 32x32 image array임.\n","        self.images_array = images_array\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.augmentor = augmentor\n","        self.pre_func = pre_func\n","\n","        # train data의 경우 \n","        self.shuffle = shuffle\n","        if self.shuffle:\n","            # 객체 생성시에 한번 데이터를 섞음. \n","            #self.on_epoch_end()\n","            pass\n","    \n","    # Sequence를 상속받은 Dataset은 batch_size 단위로 입력된 데이터를 처리함. \n","    # __len__()은 전체 데이터 건수가 주어졌을 때 batch_size단위로 몇번 데이터를 반환하는지 나타남\n","    def __len__(self):\n","        # batch_size단위로 데이터를 몇번 가져와야하는지 계산하기 위해 전체 데이터 건수를 batch_size로 나누되, 정수로 정확히 나눠지지 않을 경우 1회를 더한다. \n","        return int(np.ceil(len(self.labels) / self.batch_size))\n","    \n","    # batch_size 단위로 image_array, label_array 데이터를 가져와서 변환 후 반환\n","    # index(몇번째 배치이지) -> 해당 순서에 해당하는 batch_size 만큼의 데이터를 가공하여 반환\n","    # batch_size 개수만큼 image_array와 label_array 반환\n","    def __getitem__(self, index):\n","        # batch_size만큼 순차적으로 데이터를 가져오려면 array에서 index*self.batch_size : (index+1)*self.batch_size 만큼 가져옴\n","        # 32x32 image array를 self.batch_size만큼 가져옴. \n","        images_fetch = self.images_array[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        if self.labels is not None:\n","            label_batch = self.labels[index*self.batch_size:(index+1)*self.batch_size]\n","        \n","        # albumentation으로 만든 augmentor가 주어진다면 augmentor를 이용\n","        # albumentations : image만 변환할 수 있으므로 batch_size만큼 할당된 image_name_batch를 한 건씩 iteration하면서 변환 수행 \n","        # 변환된 image 배열값을 담을 image_batch 선언 & image_batch 배열은 float32 로 설정 \n","        image_batch = np.zeros((images_fetch.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3), dtype='float32')\n","        \n","        # batch_size에 담긴 건수만큼 iteration 하면서 opencv image load -> image augmentation 변환\n","        # augmentor가 not None일 경우 -> image_batch에 담음\n","        for image_index in range(images_fetch.shape[0]):\n","            #image = cv2.cvtColor(cv2.imread(image_name_batch[image_index]), cv2.COLOR_BGR2RGB)\n","            \n","            # 원본 image를 IMAGE_SIZE x IMAGE_SIZE 크기로 변환\n","            image = cv2.resize(images_fetch[image_index], (IMAGE_SIZE, IMAGE_SIZE))\n","\n","            # 만약 augmentor가 주어졌다면 이를 적용. \n","            if self.augmentor is not None:\n","                image = self.augmentor(image=image)['image']\n","                \n","            # 만약 scaling 함수가 입력되었다면 이를 적용하여 scaling 수행. \n","            if self.pre_func is not None:\n","                image = self.pre_func(image)\n","            \n","            # image_batch에 순차적으로 변환된 image를 담음.               \n","            image_batch[image_index] = image\n","        \n","        return image_batch, label_batch\n","    \n","    # epoch가 한번 수행이 완료 될 때마다 모델의 fit()에서 호출됨. \n","    def on_epoch_end(self):\n","        if(self.shuffle):\n","            #print('epoch end')\n","            # 원본 image배열과 label를 쌍을 맞춰서 섞어준다. scikt learn의 utils.shuffle에서 해당 기능 제공\n","            self.images_array, self.labels = sklearn.utils.shuffle(self.images_array, self.labels)\n","        else:\n","            pass"],"execution_count":null,"outputs":[]},{"metadata":{"id":"YIEIzahUmGxu"},"cell_type":"markdown","source":["\n","### 원-핫 인코딩, 학습/검증/테스트 데이터 세트 분할\n","* scaling은 원본 채널별 pixel값 - [103.939, 116.779, 123.68] 적용.\n","\n"]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"N2fpuivimGxu","outputId":"c3608c6c-9aa5-4bca-dbad-c003fc396caa"},"cell_type":"code","source":["# CIFAR10 데이터 재 로딩 및 OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n","(train_images, train_labels), (test_images, test_labels) = cifar100.load_data()\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n","\n","(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.2, random_state=2021)\n","print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169001437/169001437 [==============================] - 13s 0us/step\n","(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","(40000, 32, 32, 3) (40000, 100) (10000, 32, 32, 3) (10000, 100) (10000, 32, 32, 3) (10000, 100)\n"]}]},{"metadata":{"id":"bZBrrIJmmGxu"},"cell_type":"markdown","source":["### 학습, 검증용 CIFAR_Dataset 생성"]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"PxHU_GitmGxu","outputId":"20f19f59-f25b-4630-cbb2-12b9596e681c"},"cell_type":"code","source":["from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n","\n","tr_ds = CIFAR_Dataset(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=True, pre_func=resnet_preprocess)\n","val_ds = CIFAR_Dataset(val_images, val_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n","\n","print(next(iter(tr_ds))[0].shape, next(iter(val_ds))[0].shape)\n","print(next(iter(tr_ds))[1].shape, next(iter(val_ds))[1].shape)\n","# 채널별 값 - [103.939, 116.779, 123.68]\n","print(next(iter(tr_ds))[0][0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 128, 128, 3) (64, 128, 128, 3)\n","(64, 100) (64, 100)\n","[[[118.061     128.22101   128.32     ]\n","  [118.061     128.22101   128.32     ]\n","  [116.061     127.221     127.32     ]\n","  ...\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]]\n","\n"," [[118.061     128.22101   128.32     ]\n","  [118.061     128.22101   128.32     ]\n","  [116.061     126.221     127.32     ]\n","  ...\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]]\n","\n"," [[117.061     127.221     127.32     ]\n","  [117.061     127.221     127.32     ]\n","  [115.061     125.221     126.32     ]\n","  ...\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]\n","  [139.061     130.22101   118.32     ]]\n","\n"," ...\n","\n"," [[-23.939003  -49.779     -66.68     ]\n","  [-23.939003  -49.779     -66.68     ]\n","  [-24.939003  -50.779     -67.68     ]\n","  ...\n","  [-21.939003    9.221001   51.32     ]\n","  [-29.939003    3.2210007  48.32     ]\n","  [-29.939003    3.2210007  48.32     ]]\n","\n"," [[-23.939003  -49.779     -66.68     ]\n","  [-23.939003  -49.779     -66.68     ]\n","  [-24.939003  -49.779     -66.68     ]\n","  ...\n","  [-21.939003    9.221001   51.32     ]\n","  [-29.939003    3.2210007  48.32     ]\n","  [-29.939003    3.2210007  48.32     ]]\n","\n"," [[-23.939003  -49.779     -66.68     ]\n","  [-23.939003  -49.779     -66.68     ]\n","  [-23.939003  -49.779     -66.68     ]\n","  ...\n","  [-21.939003    9.221001   51.32     ]\n","  [-29.939003    3.2210007  48.32     ]\n","  [-29.939003    3.2210007  48.32     ]]]\n"]}]},{"metadata":{"id":"zuB0gFGTmGxu"},"cell_type":"markdown","source":["### 1) ResNet50 (모델 생성) 후 학습/평가\n","* 초기 learning_rate 0.001\n","\n"]},{"metadata":{"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"U5vPi0HfmGxu","outputId":"3ab869fa-6ee6-4377-dd99-ff895330c9df"},"cell_type":"code","source":["resnet_model = create_resnet(in_shape=(128, 128, 3), n_classes=100)\n","\n","resnet_model.compile(optimizer=Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n","rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, mode='min', verbose=1)\n","ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n","\n","history = resnet_model.fit(tr_ds, epochs=10, \n","                    #steps_per_epoch=int(np.ceil(tr_images.shape[0]/BATCH_SIZE)),\n","                    validation_data=val_ds, \n","                    #validation_steps=int(np.ceil(val_images.shape[0]/BATCH_SIZE)), \n","                    callbacks=[rlr_cb, ely_cb]\n","                   )"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_3[0][0]']                \n","                                                                                                  \n"," conv (Conv2D)                  (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n","                                                                                                  \n"," bn_conv1 (BatchNormalization)  (None, 64, 64, 64)   256         ['conv[0][0]']                   \n","                                                                                                  \n"," activation_71 (Activation)     (None, 64, 64, 64)   0           ['bn_conv1[0][0]']               \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['activation_71[0][0]']          \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 64)  0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," res2a_branch2a (Conv2D)        (None, 32, 32, 64)   4160        ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," bn2a_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_72 (Activation)     (None, 32, 32, 64)   0           ['bn2a_branch2a[0][0]']          \n","                                                                                                  \n"," res2a_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_72[0][0]']          \n","                                                                                                  \n"," bn2a_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_73 (Activation)     (None, 32, 32, 64)   0           ['bn2a_branch2b[0][0]']          \n","                                                                                                  \n"," res2a_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_73[0][0]']          \n","                                                                                                  \n"," res2a_branch1 (Conv2D)         (None, 32, 32, 256)  16640       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," bn2a_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn2a_branch1 (BatchNormalizati  (None, 32, 32, 256)  1024       ['res2a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_23 (Add)                   (None, 32, 32, 256)  0           ['bn2a_branch2c[0][0]',          \n","                                                                  'bn2a_branch1[0][0]']           \n","                                                                                                  \n"," activation_74 (Activation)     (None, 32, 32, 256)  0           ['add_23[0][0]']                 \n","                                                                                                  \n"," res2b_branch2a (Conv2D)        (None, 32, 32, 64)   16448       ['activation_74[0][0]']          \n","                                                                                                  \n"," bn2b_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_75 (Activation)     (None, 32, 32, 64)   0           ['bn2b_branch2a[0][0]']          \n","                                                                                                  \n"," res2b_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_75[0][0]']          \n","                                                                                                  \n"," bn2b_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_76 (Activation)     (None, 32, 32, 64)   0           ['bn2b_branch2b[0][0]']          \n","                                                                                                  \n"," res2b_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_76[0][0]']          \n","                                                                                                  \n"," bn2b_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_24 (Add)                   (None, 32, 32, 256)  0           ['activation_74[0][0]',          \n","                                                                  'bn2b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_77 (Activation)     (None, 32, 32, 256)  0           ['add_24[0][0]']                 \n","                                                                                                  \n"," res2c_branch2a (Conv2D)        (None, 32, 32, 64)   16448       ['activation_77[0][0]']          \n","                                                                                                  \n"," bn2c_branch2a (BatchNormalizat  (None, 32, 32, 64)  256         ['res2c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_78 (Activation)     (None, 32, 32, 64)   0           ['bn2c_branch2a[0][0]']          \n","                                                                                                  \n"," res2c_branch2b (Conv2D)        (None, 32, 32, 64)   36928       ['activation_78[0][0]']          \n","                                                                                                  \n"," bn2c_branch2b (BatchNormalizat  (None, 32, 32, 64)  256         ['res2c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_79 (Activation)     (None, 32, 32, 64)   0           ['bn2c_branch2b[0][0]']          \n","                                                                                                  \n"," res2c_branch2c (Conv2D)        (None, 32, 32, 256)  16640       ['activation_79[0][0]']          \n","                                                                                                  \n"," bn2c_branch2c (BatchNormalizat  (None, 32, 32, 256)  1024       ['res2c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_25 (Add)                   (None, 32, 32, 256)  0           ['activation_77[0][0]',          \n","                                                                  'bn2c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_80 (Activation)     (None, 32, 32, 256)  0           ['add_25[0][0]']                 \n","                                                                                                  \n"," res3a_branch2a (Conv2D)        (None, 16, 16, 128)  32896       ['activation_80[0][0]']          \n","                                                                                                  \n"," bn3a_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_81 (Activation)     (None, 16, 16, 128)  0           ['bn3a_branch2a[0][0]']          \n","                                                                                                  \n"," res3a_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_81[0][0]']          \n","                                                                                                  \n"," bn3a_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_82 (Activation)     (None, 16, 16, 128)  0           ['bn3a_branch2b[0][0]']          \n","                                                                                                  \n"," res3a_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_82[0][0]']          \n","                                                                                                  \n"," res3a_branch1 (Conv2D)         (None, 16, 16, 512)  131584      ['activation_80[0][0]']          \n","                                                                                                  \n"," bn3a_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn3a_branch1 (BatchNormalizati  (None, 16, 16, 512)  2048       ['res3a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_26 (Add)                   (None, 16, 16, 512)  0           ['bn3a_branch2c[0][0]',          \n","                                                                  'bn3a_branch1[0][0]']           \n","                                                                                                  \n"," activation_83 (Activation)     (None, 16, 16, 512)  0           ['add_26[0][0]']                 \n","                                                                                                  \n"," res3b_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_83[0][0]']          \n","                                                                                                  \n"," bn3b_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_84 (Activation)     (None, 16, 16, 128)  0           ['bn3b_branch2a[0][0]']          \n","                                                                                                  \n"," res3b_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_84[0][0]']          \n","                                                                                                  \n"," bn3b_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_85 (Activation)     (None, 16, 16, 128)  0           ['bn3b_branch2b[0][0]']          \n","                                                                                                  \n"," res3b_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_85[0][0]']          \n","                                                                                                  \n"," bn3b_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_27 (Add)                   (None, 16, 16, 512)  0           ['activation_83[0][0]',          \n","                                                                  'bn3b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_86 (Activation)     (None, 16, 16, 512)  0           ['add_27[0][0]']                 \n","                                                                                                  \n"," res3c_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_86[0][0]']          \n","                                                                                                  \n"," bn3c_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_87 (Activation)     (None, 16, 16, 128)  0           ['bn3c_branch2a[0][0]']          \n","                                                                                                  \n"," res3c_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_87[0][0]']          \n","                                                                                                  \n"," bn3c_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_88 (Activation)     (None, 16, 16, 128)  0           ['bn3c_branch2b[0][0]']          \n","                                                                                                  \n"," res3c_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_88[0][0]']          \n","                                                                                                  \n"," bn3c_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_28 (Add)                   (None, 16, 16, 512)  0           ['activation_86[0][0]',          \n","                                                                  'bn3c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_89 (Activation)     (None, 16, 16, 512)  0           ['add_28[0][0]']                 \n","                                                                                                  \n"," res3d_branch2a (Conv2D)        (None, 16, 16, 128)  65664       ['activation_89[0][0]']          \n","                                                                                                  \n"," bn3d_branch2a (BatchNormalizat  (None, 16, 16, 128)  512        ['res3d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_90 (Activation)     (None, 16, 16, 128)  0           ['bn3d_branch2a[0][0]']          \n","                                                                                                  \n"," res3d_branch2b (Conv2D)        (None, 16, 16, 128)  147584      ['activation_90[0][0]']          \n","                                                                                                  \n"," bn3d_branch2b (BatchNormalizat  (None, 16, 16, 128)  512        ['res3d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_91 (Activation)     (None, 16, 16, 128)  0           ['bn3d_branch2b[0][0]']          \n","                                                                                                  \n"," res3d_branch2c (Conv2D)        (None, 16, 16, 512)  66048       ['activation_91[0][0]']          \n","                                                                                                  \n"," bn3d_branch2c (BatchNormalizat  (None, 16, 16, 512)  2048       ['res3d_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_29 (Add)                   (None, 16, 16, 512)  0           ['activation_89[0][0]',          \n","                                                                  'bn3d_branch2c[0][0]']          \n","                                                                                                  \n"," activation_92 (Activation)     (None, 16, 16, 512)  0           ['add_29[0][0]']                 \n","                                                                                                  \n"," res4a_branch2a (Conv2D)        (None, 8, 8, 256)    131328      ['activation_92[0][0]']          \n","                                                                                                  \n"," bn4a_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_93 (Activation)     (None, 8, 8, 256)    0           ['bn4a_branch2a[0][0]']          \n","                                                                                                  \n"," res4a_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_93[0][0]']          \n","                                                                                                  \n"," bn4a_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_94 (Activation)     (None, 8, 8, 256)    0           ['bn4a_branch2b[0][0]']          \n","                                                                                                  \n"," res4a_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_94[0][0]']          \n","                                                                                                  \n"," res4a_branch1 (Conv2D)         (None, 8, 8, 1024)   525312      ['activation_92[0][0]']          \n","                                                                                                  \n"," bn4a_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn4a_branch1 (BatchNormalizati  (None, 8, 8, 1024)  4096        ['res4a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_30 (Add)                   (None, 8, 8, 1024)   0           ['bn4a_branch2c[0][0]',          \n","                                                                  'bn4a_branch1[0][0]']           \n","                                                                                                  \n"," activation_95 (Activation)     (None, 8, 8, 1024)   0           ['add_30[0][0]']                 \n","                                                                                                  \n"," res4b_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_95[0][0]']          \n","                                                                                                  \n"," bn4b_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_96 (Activation)     (None, 8, 8, 256)    0           ['bn4b_branch2a[0][0]']          \n","                                                                                                  \n"," res4b_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_96[0][0]']          \n","                                                                                                  \n"," bn4b_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_97 (Activation)     (None, 8, 8, 256)    0           ['bn4b_branch2b[0][0]']          \n","                                                                                                  \n"," res4b_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_97[0][0]']          \n","                                                                                                  \n"," bn4b_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_31 (Add)                   (None, 8, 8, 1024)   0           ['activation_95[0][0]',          \n","                                                                  'bn4b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_98 (Activation)     (None, 8, 8, 1024)   0           ['add_31[0][0]']                 \n","                                                                                                  \n"," res4c_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_98[0][0]']          \n","                                                                                                  \n"," bn4c_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_99 (Activation)     (None, 8, 8, 256)    0           ['bn4c_branch2a[0][0]']          \n","                                                                                                  \n"," res4c_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_99[0][0]']          \n","                                                                                                  \n"," bn4c_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_100 (Activation)    (None, 8, 8, 256)    0           ['bn4c_branch2b[0][0]']          \n","                                                                                                  \n"," res4c_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_100[0][0]']         \n","                                                                                                  \n"," bn4c_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_32 (Add)                   (None, 8, 8, 1024)   0           ['activation_98[0][0]',          \n","                                                                  'bn4c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_101 (Activation)    (None, 8, 8, 1024)   0           ['add_32[0][0]']                 \n","                                                                                                  \n"," res4d_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_101[0][0]']         \n","                                                                                                  \n"," bn4d_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4d_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_102 (Activation)    (None, 8, 8, 256)    0           ['bn4d_branch2a[0][0]']          \n","                                                                                                  \n"," res4d_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_102[0][0]']         \n","                                                                                                  \n"," bn4d_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4d_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_103 (Activation)    (None, 8, 8, 256)    0           ['bn4d_branch2b[0][0]']          \n","                                                                                                  \n"," res4d_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_103[0][0]']         \n","                                                                                                  \n"," bn4d_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4d_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_33 (Add)                   (None, 8, 8, 1024)   0           ['activation_101[0][0]',         \n","                                                                  'bn4d_branch2c[0][0]']          \n","                                                                                                  \n"," activation_104 (Activation)    (None, 8, 8, 1024)   0           ['add_33[0][0]']                 \n","                                                                                                  \n"," res4e_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_104[0][0]']         \n","                                                                                                  \n"," bn4e_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4e_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_105 (Activation)    (None, 8, 8, 256)    0           ['bn4e_branch2a[0][0]']          \n","                                                                                                  \n"," res4e_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_105[0][0]']         \n","                                                                                                  \n"," bn4e_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4e_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_106 (Activation)    (None, 8, 8, 256)    0           ['bn4e_branch2b[0][0]']          \n","                                                                                                  \n"," res4e_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_106[0][0]']         \n","                                                                                                  \n"," bn4e_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4e_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_34 (Add)                   (None, 8, 8, 1024)   0           ['activation_104[0][0]',         \n","                                                                  'bn4e_branch2c[0][0]']          \n","                                                                                                  \n"," activation_107 (Activation)    (None, 8, 8, 1024)   0           ['add_34[0][0]']                 \n","                                                                                                  \n"," res4f_branch2a (Conv2D)        (None, 8, 8, 256)    262400      ['activation_107[0][0]']         \n","                                                                                                  \n"," bn4f_branch2a (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4f_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_108 (Activation)    (None, 8, 8, 256)    0           ['bn4f_branch2a[0][0]']          \n","                                                                                                  \n"," res4f_branch2b (Conv2D)        (None, 8, 8, 256)    590080      ['activation_108[0][0]']         \n","                                                                                                  \n"," bn4f_branch2b (BatchNormalizat  (None, 8, 8, 256)   1024        ['res4f_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_109 (Activation)    (None, 8, 8, 256)    0           ['bn4f_branch2b[0][0]']          \n","                                                                                                  \n"," res4f_branch2c (Conv2D)        (None, 8, 8, 1024)   263168      ['activation_109[0][0]']         \n","                                                                                                  \n"," bn4f_branch2c (BatchNormalizat  (None, 8, 8, 1024)  4096        ['res4f_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_35 (Add)                   (None, 8, 8, 1024)   0           ['activation_107[0][0]',         \n","                                                                  'bn4f_branch2c[0][0]']          \n","                                                                                                  \n"," activation_110 (Activation)    (None, 8, 8, 1024)   0           ['add_35[0][0]']                 \n","                                                                                                  \n"," res5a_branch2a (Conv2D)        (None, 4, 4, 512)    524800      ['activation_110[0][0]']         \n","                                                                                                  \n"," bn5a_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5a_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_111 (Activation)    (None, 4, 4, 512)    0           ['bn5a_branch2a[0][0]']          \n","                                                                                                  \n"," res5a_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_111[0][0]']         \n","                                                                                                  \n"," bn5a_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5a_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_112 (Activation)    (None, 4, 4, 512)    0           ['bn5a_branch2b[0][0]']          \n","                                                                                                  \n"," res5a_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_112[0][0]']         \n","                                                                                                  \n"," res5a_branch1 (Conv2D)         (None, 4, 4, 2048)   2099200     ['activation_110[0][0]']         \n","                                                                                                  \n"," bn5a_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5a_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," bn5a_branch1 (BatchNormalizati  (None, 4, 4, 2048)  8192        ['res5a_branch1[0][0]']          \n"," on)                                                                                              \n","                                                                                                  \n"," add_36 (Add)                   (None, 4, 4, 2048)   0           ['bn5a_branch2c[0][0]',          \n","                                                                  'bn5a_branch1[0][0]']           \n","                                                                                                  \n"," activation_113 (Activation)    (None, 4, 4, 2048)   0           ['add_36[0][0]']                 \n","                                                                                                  \n"," res5b_branch2a (Conv2D)        (None, 4, 4, 512)    1049088     ['activation_113[0][0]']         \n","                                                                                                  \n"," bn5b_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5b_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_114 (Activation)    (None, 4, 4, 512)    0           ['bn5b_branch2a[0][0]']          \n","                                                                                                  \n"," res5b_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_114[0][0]']         \n","                                                                                                  \n"," bn5b_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5b_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_115 (Activation)    (None, 4, 4, 512)    0           ['bn5b_branch2b[0][0]']          \n","                                                                                                  \n"," res5b_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_115[0][0]']         \n","                                                                                                  \n"," bn5b_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5b_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_37 (Add)                   (None, 4, 4, 2048)   0           ['activation_113[0][0]',         \n","                                                                  'bn5b_branch2c[0][0]']          \n","                                                                                                  \n"," activation_116 (Activation)    (None, 4, 4, 2048)   0           ['add_37[0][0]']                 \n","                                                                                                  \n"," res5c_branch2a (Conv2D)        (None, 4, 4, 512)    1049088     ['activation_116[0][0]']         \n","                                                                                                  \n"," bn5c_branch2a (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5c_branch2a[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_117 (Activation)    (None, 4, 4, 512)    0           ['bn5c_branch2a[0][0]']          \n","                                                                                                  \n"," res5c_branch2b (Conv2D)        (None, 4, 4, 512)    2359808     ['activation_117[0][0]']         \n","                                                                                                  \n"," bn5c_branch2b (BatchNormalizat  (None, 4, 4, 512)   2048        ['res5c_branch2b[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," activation_118 (Activation)    (None, 4, 4, 512)    0           ['bn5c_branch2b[0][0]']          \n","                                                                                                  \n"," res5c_branch2c (Conv2D)        (None, 4, 4, 2048)   1050624     ['activation_118[0][0]']         \n","                                                                                                  \n"," bn5c_branch2c (BatchNormalizat  (None, 4, 4, 2048)  8192        ['res5c_branch2c[0][0]']         \n"," ion)                                                                                             \n","                                                                                                  \n"," add_38 (Add)                   (None, 4, 4, 2048)   0           ['activation_116[0][0]',         \n","                                                                  'bn5c_branch2c[0][0]']          \n","                                                                                                  \n"," activation_119 (Activation)    (None, 4, 4, 2048)   0           ['add_38[0][0]']                 \n","                                                                                                  \n"," avg_pool (GlobalAveragePooling  (None, 2048)        0           ['activation_119[0][0]']         \n"," 2D)                                                                                              \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 2048)         0           ['avg_pool[0][0]']               \n","                                                                                                  \n"," fc_01 (Dense)                  (None, 200)          409800      ['dropout_2[0][0]']              \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n","                                                                                                  \n"," fc_final (Dense)               (None, 100)          20100       ['dropout_3[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 24,017,612\n","Trainable params: 23,964,492\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","625/625 [==============================] - 160s 247ms/step - loss: 4.7057 - accuracy: 0.0104 - val_loss: 4.6096 - val_accuracy: 0.0071 - lr: 0.0100\n","Epoch 2/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0089 - val_loss: 4.6109 - val_accuracy: 0.0077 - lr: 0.0100\n","Epoch 3/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6091 - accuracy: 0.0102 - val_loss: 4.6100 - val_accuracy: 0.0100 - lr: 0.0100\n","Epoch 4/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6090 - accuracy: 0.0094 - val_loss: 4.6095 - val_accuracy: 0.0074 - lr: 0.0100\n","Epoch 5/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0102 - val_loss: 4.6105 - val_accuracy: 0.0090 - lr: 0.0100\n","Epoch 6/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6090 - accuracy: 0.0102 - val_loss: 4.6113 - val_accuracy: 0.0074 - lr: 0.0100\n","Epoch 7/10\n","625/625 [==============================] - ETA: 0s - loss: 4.6088 - accuracy: 0.0093\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6088 - accuracy: 0.0093 - val_loss: 4.6101 - val_accuracy: 0.0104 - lr: 0.0100\n","Epoch 8/10\n","625/625 [==============================] - 153s 244ms/step - loss: 4.6068 - accuracy: 0.0094 - val_loss: 4.6083 - val_accuracy: 0.0104 - lr: 0.0020\n","Epoch 9/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6060 - accuracy: 0.0088 - val_loss: 4.6084 - val_accuracy: 0.0082 - lr: 0.0020\n","Epoch 10/10\n","625/625 [==============================] - 153s 245ms/step - loss: 4.6059 - accuracy: 0.0099 - val_loss: 4.6085 - val_accuracy: 0.0074 - lr: 0.0020\n"]}]},{"metadata":{"trusted":true,"id":"gImZ32Z0mGxv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"efc4b0ef-8751-42bc-a23a-6d0d8ac6e87c"},"cell_type":"code","source":["test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n","resnet_model.evaluate(test_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["157/157 [==============================] - 12s 73ms/step - loss: 4.6056 - accuracy: 0.0100\n"]},{"output_type":"execute_result","data":{"text/plain":["[4.605584144592285, 0.009999999776482582]"]},"metadata":{},"execution_count":16}]},{"metadata":{"id":"oq2rHrXsmGxv"},"cell_type":"markdown","source":["### 2) ResNet50 (Pretrained 모델)로 학습/평가"]},{"metadata":{"trusted":true,"id":"ivQzaa25mGxv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e01fb90e-b1c7-4adf-f150-5f71c68629d7"},"cell_type":"code","source":["from tensorflow.keras.applications import ResNet50\n","\n","input_tensor = Input(shape=(128, 128, 3))\n","base_model = ResNet50(include_top=False, weights=None, input_tensor=input_tensor)\n","bm_output = base_model.output\n","\n","# classification dense layer와 연결 전 GlobalAveragePooling 수행 \n","x = GlobalAveragePooling2D(name='avg_pool')(bm_output)\n","x = Dropout(rate=0.5)(x)\n","x = Dense(200, activation='relu', name='fc_01')(x)\n","x = Dropout(rate=0.5)(x)\n","output = Dense(100, activation='softmax', name='fc_final')(x)\n","\n","pr_model = Model(inputs=input_tensor, outputs=output, name='resnet50')\n","pr_model.summary()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"resnet50\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_5 (InputLayer)           [(None, 128, 128, 3  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv1_pad (ZeroPadding2D)      (None, 134, 134, 3)  0           ['input_5[0][0]']                \n","                                                                                                  \n"," conv1_conv (Conv2D)            (None, 64, 64, 64)   9472        ['conv1_pad[0][0]']              \n","                                                                                                  \n"," conv1_bn (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1_conv[0][0]']             \n","                                                                                                  \n"," conv1_relu (Activation)        (None, 64, 64, 64)   0           ['conv1_bn[0][0]']               \n","                                                                                                  \n"," pool1_pad (ZeroPadding2D)      (None, 66, 66, 64)   0           ['conv1_relu[0][0]']             \n","                                                                                                  \n"," pool1_pool (MaxPooling2D)      (None, 32, 32, 64)   0           ['pool1_pad[0][0]']              \n","                                                                                                  \n"," conv2_block1_1_conv (Conv2D)   (None, 32, 32, 64)   4160        ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block1_0_conv (Conv2D)   (None, 32, 32, 256)  16640       ['pool1_pool[0][0]']             \n","                                                                                                  \n"," conv2_block1_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block1_0_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block1_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_0_bn[0][0]',      \n","                                                                  'conv2_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block1_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block1_add[0][0]']       \n","                                                                                                  \n"," conv2_block2_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block1_out[0][0]']       \n","                                                                                                  \n"," conv2_block2_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block2_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block2_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block2_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block2_add (Add)         (None, 32, 32, 256)  0           ['conv2_block1_out[0][0]',       \n","                                                                  'conv2_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block2_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block2_add[0][0]']       \n","                                                                                                  \n"," conv2_block3_1_conv (Conv2D)   (None, 32, 32, 64)   16448       ['conv2_block2_out[0][0]']       \n","                                                                                                  \n"," conv2_block3_1_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_1_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block3_2_conv (Conv2D)   (None, 32, 32, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv2_block3_2_bn (BatchNormal  (None, 32, 32, 64)  256         ['conv2_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_2_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv2_block3_3_conv (Conv2D)   (None, 32, 32, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv2_block3_3_bn (BatchNormal  (None, 32, 32, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv2_block3_add (Add)         (None, 32, 32, 256)  0           ['conv2_block2_out[0][0]',       \n","                                                                  'conv2_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv2_block3_out (Activation)  (None, 32, 32, 256)  0           ['conv2_block3_add[0][0]']       \n","                                                                                                  \n"," conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  32896       ['conv2_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block1_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block1_0_conv (Conv2D)   (None, 16, 16, 512)  131584      ['conv2_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block1_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block1_0_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block1_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_0_bn[0][0]',      \n","                                                                  'conv3_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block1_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block1_add[0][0]']       \n","                                                                                                  \n"," conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block1_out[0][0]']       \n","                                                                                                  \n"," conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block2_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block2_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block2_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block2_add (Add)         (None, 16, 16, 512)  0           ['conv3_block1_out[0][0]',       \n","                                                                  'conv3_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block2_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block2_add[0][0]']       \n","                                                                                                  \n"," conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block2_out[0][0]']       \n","                                                                                                  \n"," conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block3_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block3_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block3_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block3_add (Add)         (None, 16, 16, 512)  0           ['conv3_block2_out[0][0]',       \n","                                                                  'conv3_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block3_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block3_add[0][0]']       \n","                                                                                                  \n"," conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  65664       ['conv3_block3_out[0][0]']       \n","                                                                                                  \n"," conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block4_2_conv (Conv2D)   (None, 16, 16, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n","                                                                                                  \n"," conv3_block4_2_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_2_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv3_block4_3_conv (Conv2D)   (None, 16, 16, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv3_block4_3_bn (BatchNormal  (None, 16, 16, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv3_block4_add (Add)         (None, 16, 16, 512)  0           ['conv3_block3_out[0][0]',       \n","                                                                  'conv3_block4_3_bn[0][0]']      \n","                                                                                                  \n"," conv3_block4_out (Activation)  (None, 16, 16, 512)  0           ['conv3_block4_add[0][0]']       \n","                                                                                                  \n"," conv4_block1_1_conv (Conv2D)   (None, 8, 8, 256)    131328      ['conv3_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block1_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block1_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block1_0_conv (Conv2D)   (None, 8, 8, 1024)   525312      ['conv3_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block1_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block1_0_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block1_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n","                                                                  'conv4_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block1_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block1_add[0][0]']       \n","                                                                                                  \n"," conv4_block2_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block1_out[0][0]']       \n","                                                                                                  \n"," conv4_block2_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block2_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block2_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block2_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block2_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block1_out[0][0]',       \n","                                                                  'conv4_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block2_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block2_add[0][0]']       \n","                                                                                                  \n"," conv4_block3_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block2_out[0][0]']       \n","                                                                                                  \n"," conv4_block3_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block3_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block3_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block3_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block3_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block2_out[0][0]',       \n","                                                                  'conv4_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block3_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block3_add[0][0]']       \n","                                                                                                  \n"," conv4_block4_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block3_out[0][0]']       \n","                                                                                                  \n"," conv4_block4_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block4_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block4_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block4_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block4_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block4_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block3_out[0][0]',       \n","                                                                  'conv4_block4_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block4_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block4_add[0][0]']       \n","                                                                                                  \n"," conv4_block5_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block4_out[0][0]']       \n","                                                                                                  \n"," conv4_block5_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block5_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block5_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block5_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block5_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block5_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block4_out[0][0]',       \n","                                                                  'conv4_block5_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block5_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block5_add[0][0]']       \n","                                                                                                  \n"," conv4_block6_1_conv (Conv2D)   (None, 8, 8, 256)    262400      ['conv4_block5_out[0][0]']       \n","                                                                                                  \n"," conv4_block6_1_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_1_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block6_2_conv (Conv2D)   (None, 8, 8, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n","                                                                                                  \n"," conv4_block6_2_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_2_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block6_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv4_block6_3_conv (Conv2D)   (None, 8, 8, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n","                                                                                                  \n"," conv4_block6_3_bn (BatchNormal  (None, 8, 8, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv4_block6_add (Add)         (None, 8, 8, 1024)   0           ['conv4_block5_out[0][0]',       \n","                                                                  'conv4_block6_3_bn[0][0]']      \n","                                                                                                  \n"," conv4_block6_out (Activation)  (None, 8, 8, 1024)   0           ['conv4_block6_add[0][0]']       \n","                                                                                                  \n"," conv5_block1_1_conv (Conv2D)   (None, 4, 4, 512)    524800      ['conv4_block6_out[0][0]']       \n","                                                                                                  \n"," conv5_block1_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block1_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block1_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block1_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block1_0_conv (Conv2D)   (None, 4, 4, 2048)   2099200     ['conv4_block6_out[0][0]']       \n","                                                                                                  \n"," conv5_block1_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block1_0_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block1_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n","                                                                  'conv5_block1_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block1_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block1_add[0][0]']       \n","                                                                                                  \n"," conv5_block2_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block1_out[0][0]']       \n","                                                                                                  \n"," conv5_block2_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block2_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block2_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block2_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block2_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block2_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block2_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block1_out[0][0]',       \n","                                                                  'conv5_block2_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block2_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block2_add[0][0]']       \n","                                                                                                  \n"," conv5_block3_1_conv (Conv2D)   (None, 4, 4, 512)    1049088     ['conv5_block2_out[0][0]']       \n","                                                                                                  \n"," conv5_block3_1_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_1_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_1_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block3_2_conv (Conv2D)   (None, 4, 4, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n","                                                                                                  \n"," conv5_block3_2_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_2_relu (Activatio  (None, 4, 4, 512)   0           ['conv5_block3_2_bn[0][0]']      \n"," n)                                                                                               \n","                                                                                                  \n"," conv5_block3_3_conv (Conv2D)   (None, 4, 4, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n","                                                                                                  \n"," conv5_block3_3_bn (BatchNormal  (None, 4, 4, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n"," ization)                                                                                         \n","                                                                                                  \n"," conv5_block3_add (Add)         (None, 4, 4, 2048)   0           ['conv5_block2_out[0][0]',       \n","                                                                  'conv5_block3_3_bn[0][0]']      \n","                                                                                                  \n"," conv5_block3_out (Activation)  (None, 4, 4, 2048)   0           ['conv5_block3_add[0][0]']       \n","                                                                                                  \n"," avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n"," 2D)                                                                                              \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 2048)         0           ['avg_pool[0][0]']               \n","                                                                                                  \n"," fc_01 (Dense)                  (None, 200)          409800      ['dropout_6[0][0]']              \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, 200)          0           ['fc_01[0][0]']                  \n","                                                                                                  \n"," fc_final (Dense)               (None, 100)          20100       ['dropout_7[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 24,017,612\n","Trainable params: 23,964,492\n","Non-trainable params: 53,120\n","__________________________________________________________________________________________________\n"]}]},{"metadata":{"trusted":true,"id":"f5Rb-lCSmGxv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ac8be47-0bdd-4aa5-d0fb-398876b74f44"},"cell_type":"code","source":["pr_model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","history = pr_model.fit(tr_ds, epochs=40, \n","                    validation_data=val_ds,\n","                    callbacks=[rlr_cb, ely_cb]\n","                   )\n","\n","test_ds = CIFAR_Dataset(test_images, test_oh_labels, batch_size=BATCH_SIZE, augmentor=None, shuffle=False, pre_func=resnet_preprocess)\n","pr_model.evaluate(test_ds)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","625/625 [==============================] - 163s 253ms/step - loss: 3.0745 - accuracy: 0.2450 - val_loss: 2.8890 - val_accuracy: 0.2828 - lr: 1.0000e-04\n","Epoch 2/40\n","625/625 [==============================] - 157s 251ms/step - loss: 2.9071 - accuracy: 0.2743 - val_loss: 2.7830 - val_accuracy: 0.3066 - lr: 1.0000e-04\n","Epoch 3/40\n","625/625 [==============================] - 157s 251ms/step - loss: 2.7631 - accuracy: 0.3007 - val_loss: 2.7235 - val_accuracy: 0.3255 - lr: 1.0000e-04\n","Epoch 4/40\n","625/625 [==============================] - 157s 251ms/step - loss: 2.5685 - accuracy: 0.3397 - val_loss: 2.6092 - val_accuracy: 0.3416 - lr: 1.0000e-04\n","Epoch 5/40\n","625/625 [==============================] - 157s 251ms/step - loss: 2.3776 - accuracy: 0.3742 - val_loss: 2.6513 - val_accuracy: 0.3365 - lr: 1.0000e-04\n","Epoch 6/40\n","625/625 [==============================] - 157s 251ms/step - loss: 2.2249 - accuracy: 0.4089 - val_loss: 2.5796 - val_accuracy: 0.3614 - lr: 1.0000e-04\n","Epoch 7/40\n","625/625 [==============================] - 157s 251ms/step - loss: 1.9740 - accuracy: 0.4657 - val_loss: 2.7036 - val_accuracy: 0.3401 - lr: 1.0000e-04\n","Epoch 8/40\n","625/625 [==============================] - 157s 251ms/step - loss: 1.7446 - accuracy: 0.5182 - val_loss: 2.6064 - val_accuracy: 0.3834 - lr: 1.0000e-04\n","Epoch 9/40\n","625/625 [==============================] - ETA: 0s - loss: 1.5962 - accuracy: 0.5526\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n","625/625 [==============================] - 157s 251ms/step - loss: 1.5962 - accuracy: 0.5526 - val_loss: 2.6634 - val_accuracy: 0.3829 - lr: 1.0000e-04\n","Epoch 10/40\n","625/625 [==============================] - 157s 251ms/step - loss: 1.0426 - accuracy: 0.6884 - val_loss: 2.6142 - val_accuracy: 0.4283 - lr: 2.0000e-05\n","Epoch 11/40\n","625/625 [==============================] - 157s 251ms/step - loss: 0.8130 - accuracy: 0.7500 - val_loss: 2.8256 - val_accuracy: 0.4268 - lr: 2.0000e-05\n","Epoch 12/40\n","625/625 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.7893\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n","625/625 [==============================] - 157s 251ms/step - loss: 0.6643 - accuracy: 0.7893 - val_loss: 3.1391 - val_accuracy: 0.4181 - lr: 2.0000e-05\n","Epoch 13/40\n","625/625 [==============================] - 157s 251ms/step - loss: 0.5292 - accuracy: 0.8280 - val_loss: 3.1750 - val_accuracy: 0.4232 - lr: 4.0000e-06\n","Epoch 14/40\n","625/625 [==============================] - 157s 251ms/step - loss: 0.4755 - accuracy: 0.8433 - val_loss: 3.2412 - val_accuracy: 0.4244 - lr: 4.0000e-06\n","Epoch 15/40\n","625/625 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.8521\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n","625/625 [==============================] - 157s 251ms/step - loss: 0.4461 - accuracy: 0.8521 - val_loss: 3.3093 - val_accuracy: 0.4237 - lr: 4.0000e-06\n","Epoch 16/40\n","625/625 [==============================] - 157s 251ms/step - loss: 0.4182 - accuracy: 0.8615 - val_loss: 3.3108 - val_accuracy: 0.4244 - lr: 8.0000e-07\n","Epoch 16: early stopping\n","157/157 [==============================] - 12s 74ms/step - loss: 3.2143 - accuracy: 0.4342\n"]},{"output_type":"execute_result","data":{"text/plain":["[3.214346408843994, 0.4341999888420105]"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["#Pytorch Image Classification\n","\n","* tensorflow로 구현된 내용을 필자가 자주 활용하는 pytorch로 변환하여 과제 수행\n","* 전체 Resnet을 구현하지는 않고, torchvision에서 이미 구현된 resnet을 활용하여 과제 수행\n","* 나머지 사항들은 각주로서 설명"],"metadata":{"id":"uuXGbpXj-nit"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision import transforms \n","\n","if torch.cuda.is_available():\n","  device='cuda'\n","else:\n","  device='cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ap5spZtn70OV","outputId":"27e334af-f442-4538-ff80-43e7c00f842d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["* Pytorch identity_block/conv_block/first_conv 구현\n","     \n","     *사실 Pytorch 특성상 이렇게 구현하면 안되는데..(pytorch는 클래스 중심으로 구현) tensorflow의 block들을 직관적으로 구현하고 이해하고자 부득이하게 단일 메소드로 구현.. "],"metadata":{"id":"k6ZTnbtCEBTK"}},{"cell_type":"code","source":["from torch import nn\n","\n","def identity_block(input_tensor, middle_kernel_size, filters):\n","\n","  #def __init__():\n","  #self.input_tensor=input_tensor\n","  #self.middle_kernel_size=middle_kernel_size\n","  #self.filters=filters\n","\n","  #def _make_layers(input_tensor, middle_kernel_size, filters):\n","  filter1, filter2, filter3=filters\n","  relu=nn.ReLU()\n","  conv1=nn.Conv2d(input_tensor.shape[1], filter1, kernel_size=(1,1))\n","  bnorm1=nn.BatchNorm2d(filter1)\n","\n","  conv2=nn.Conv2d(filter1, filter2, kernel_size=middle_kernel_size)\n","  bnorm2=nn.BatchNorm2d(filter2)\n","\n","  conv3=nn.Conv2d(filter2, filter3, kernel_size=(1,1))\n","  bnorm3=nn.BatchNorm2d(filter3)\n","\n","  #def forward():\n","  x=conv1(input_tensor)\n","  x=bnorm1(x)\n","  x=relu(x)\n","  x=conv2(x)\n","  x=bnorm2(x)\n","  x=relu(x)\n","  x=conv3(x)\n","  x=bnorm3(x)\n","  \n","  x=torch.add(input_tensor, x)\n","  x=relu(x)\n","\n","  return x"],"metadata":{"id":"UFvLGrCQ74Xb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conv_block(input_tensor, middle_kernel_size, filters, strides=(2,2)):\n","\n","\n","  #def _make_layers(input_tensor, middle_kernel_size, filters, strides):\n","  filter1, filter2, filter3=filter1\n","\n","  relu=nn.ReLU()\n","\n","  conv1=nn.Conv2d(input_tensor.shape[1], filter1, kernel_size=(1,1), stride=2)\n","  bnorm1=nn.BatchNorm2d(filter1)\n","\n","  conv2=nn.Conv2d(filter1, filter2, kernel_size=middle_kernel_size, padding=1)\n","  bnorm2=nn.BatchNorm2d(filter2)\n","\n","  conv3=nn.Conv2d(filter2, filter3, kernel_size=(1,1))\n","  bnorm3=nn.BatchNorm2d(filter3)\n","\n","  shortcut1=nn.Conv2d(filter3, filter3, kernel_size=(1,1), stride=strides)\n","  shortcut2=nn.BatchNorm2d(filter3)\n","\n","  #def forward():\n","  x=conv1(input_tensor)\n","  x=bnorm1(x)\n","  x=relu(x)\n","  x=conv2(x)\n","  x=bnorm2(x)\n","  x=relu(x)\n","  x=conv3(x)\n","  x=bnorm3(x)\n","  \n","  shortcut=shortcut1(input_tensor)\n","  shortcut=shortcut2(shortcut)\n","\n","  x=torch.add(x, shortcut)\n","  x=relu(x)\n","\n","  return x"],"metadata":{"id":"TPYu0Fyo75H0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def first_conv(input_tensor):\n","\n","  #def _make_layers(input_tensor):\n","  pad1=nn.ZeroPad2d((3,3))\n","  conv1=nn.Conv2d(64, (7,7),strides=(2,2))\n","  bnorm1=nn.BatchNorm2d(64)\n","  relu=nn.ReLU()\n","\n","  pad2=nn.ZeroPad2d((1,1))\n","  maxpool=nn.MaxPool2d((3,3),strides=(2,2))\n","\n","  #def forward():\n","  x=pad1(input_tensor)\n","  x=conv1(x)\n","  x=bnorm1(x)\n","  x=relu(x)\n","\n","  x=pad2(x)\n","  x=maxpool(x)\n","\n","  return x"],"metadata":{"id":"hIYDgwyj77He"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Pytorch Resnet"],"metadata":{"id":"cOJ2H2jQFHkN"}},{"cell_type":"code","source":["tr_data=datasets.CIFAR100(root='data',\n","                          train=True,\n","                          download=True,\n","                          )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5gsHtwFgHRi","outputId":"752448b0-6a2a-4dd6-e75d-0bf3a3ef715a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["#Image Normalization\n","x = np.concatenate([np.asarray(tr_data[i][0]) for i in range(len(tr_data))])\n","\n","mean = np.mean(x, axis=(0, 1))/255\n","std = np.std(x, axis=(0, 1))/255\n","\n","mean=mean.tolist()\n","std=std.tolist()"],"metadata":{"id":"KwvZaL1If1Rd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tr_data=datasets.CIFAR100(root='data',\n","                          train=True,\n","                          download=True,\n","                          transform=transforms.Compose([ #Simple Augmentation 적용\n","                              transforms.Resize(224), #원래 224*224 이미지에 적합한 모델이므로 Resize\n","                              transforms.RandomCrop(224, padding=4,padding_mode='reflect'), #224*224 image에서 image RandomCrop(*image augmentation)\n","                              transforms.RandomHorizontalFlip(), #horizontal 방향으로 사진 뒤집기\n","                              transforms.ToTensor(),\n","                              transforms.Normalize(mean=mean,\n","                                     std=std,inplace=True)\n","                          ]))\n","\n","test_data=datasets.CIFAR100(root='data',\n","                          train=False,\n","                          download=True,\n","                          transform=transforms.Compose([\n","                              transforms.Resize(224),\n","                              transforms.ToTensor(),\n","                              transforms.Normalize(mean=mean,\n","                                     std=std)\n","                          ]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rYinODQV78qj","outputId":"2bf16505-c718-4f59-e63b-235dc2ecc045"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["batch_size= 32\n","\n","train_db=DataLoader(tr_data, batch_size=batch_size,shuffle=True,pin_memory=True)\n","test_db=DataLoader(test_data, batch_size=batch_size,shuffle=False,pin_memory=True)"],"metadata":{"id":"2izxV92V7-bN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False) #Resnet 호출 \n","model.to(device) #cuda 올리기\n","\n","loss_fn=nn.CrossEntropyLoss()\n","optimizer=torch.optim.Adam(model.parameters(), lr=5e-3,weight_decay=1e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MvrtoZC8BRL","outputId":"c2f26230-a969-4ef8-9e13-f1294c70f133"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"]}]},{"cell_type":"code","source":["from torchsummary import summary #model summary check\n","\n","summary(model, (3,224,224), batch_size=32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rXn_Ctd9hqlq","outputId":"17d8d213-96be-499a-f8e3-52185479768c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [32, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [32, 64, 112, 112]             128\n","              ReLU-3         [32, 64, 112, 112]               0\n","         MaxPool2d-4           [32, 64, 56, 56]               0\n","            Conv2d-5           [32, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [32, 64, 56, 56]             128\n","              ReLU-7           [32, 64, 56, 56]               0\n","            Conv2d-8           [32, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [32, 64, 56, 56]             128\n","             ReLU-10           [32, 64, 56, 56]               0\n","           Conv2d-11          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [32, 256, 56, 56]             512\n","           Conv2d-13          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [32, 256, 56, 56]             512\n","             ReLU-15          [32, 256, 56, 56]               0\n","       Bottleneck-16          [32, 256, 56, 56]               0\n","           Conv2d-17           [32, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [32, 64, 56, 56]             128\n","             ReLU-19           [32, 64, 56, 56]               0\n","           Conv2d-20           [32, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [32, 64, 56, 56]             128\n","             ReLU-22           [32, 64, 56, 56]               0\n","           Conv2d-23          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [32, 256, 56, 56]             512\n","             ReLU-25          [32, 256, 56, 56]               0\n","       Bottleneck-26          [32, 256, 56, 56]               0\n","           Conv2d-27           [32, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [32, 64, 56, 56]             128\n","             ReLU-29           [32, 64, 56, 56]               0\n","           Conv2d-30           [32, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [32, 64, 56, 56]             128\n","             ReLU-32           [32, 64, 56, 56]               0\n","           Conv2d-33          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [32, 256, 56, 56]             512\n","             ReLU-35          [32, 256, 56, 56]               0\n","       Bottleneck-36          [32, 256, 56, 56]               0\n","           Conv2d-37          [32, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [32, 128, 56, 56]             256\n","             ReLU-39          [32, 128, 56, 56]               0\n","           Conv2d-40          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [32, 128, 28, 28]             256\n","             ReLU-42          [32, 128, 28, 28]               0\n","           Conv2d-43          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [32, 512, 28, 28]           1,024\n","           Conv2d-45          [32, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n","             ReLU-47          [32, 512, 28, 28]               0\n","       Bottleneck-48          [32, 512, 28, 28]               0\n","           Conv2d-49          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [32, 128, 28, 28]             256\n","             ReLU-51          [32, 128, 28, 28]               0\n","           Conv2d-52          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [32, 128, 28, 28]             256\n","             ReLU-54          [32, 128, 28, 28]               0\n","           Conv2d-55          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [32, 512, 28, 28]           1,024\n","             ReLU-57          [32, 512, 28, 28]               0\n","       Bottleneck-58          [32, 512, 28, 28]               0\n","           Conv2d-59          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [32, 128, 28, 28]             256\n","             ReLU-61          [32, 128, 28, 28]               0\n","           Conv2d-62          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [32, 128, 28, 28]             256\n","             ReLU-64          [32, 128, 28, 28]               0\n","           Conv2d-65          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [32, 512, 28, 28]           1,024\n","             ReLU-67          [32, 512, 28, 28]               0\n","       Bottleneck-68          [32, 512, 28, 28]               0\n","           Conv2d-69          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [32, 128, 28, 28]             256\n","             ReLU-71          [32, 128, 28, 28]               0\n","           Conv2d-72          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [32, 128, 28, 28]             256\n","             ReLU-74          [32, 128, 28, 28]               0\n","           Conv2d-75          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [32, 512, 28, 28]           1,024\n","             ReLU-77          [32, 512, 28, 28]               0\n","       Bottleneck-78          [32, 512, 28, 28]               0\n","           Conv2d-79          [32, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [32, 256, 28, 28]             512\n","             ReLU-81          [32, 256, 28, 28]               0\n","           Conv2d-82          [32, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [32, 256, 14, 14]             512\n","             ReLU-84          [32, 256, 14, 14]               0\n","           Conv2d-85         [32, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [32, 1024, 14, 14]           2,048\n","           Conv2d-87         [32, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n","             ReLU-89         [32, 1024, 14, 14]               0\n","       Bottleneck-90         [32, 1024, 14, 14]               0\n","           Conv2d-91          [32, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [32, 256, 14, 14]             512\n","             ReLU-93          [32, 256, 14, 14]               0\n","           Conv2d-94          [32, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [32, 256, 14, 14]             512\n","             ReLU-96          [32, 256, 14, 14]               0\n","           Conv2d-97         [32, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [32, 1024, 14, 14]           2,048\n","             ReLU-99         [32, 1024, 14, 14]               0\n","      Bottleneck-100         [32, 1024, 14, 14]               0\n","          Conv2d-101          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [32, 256, 14, 14]             512\n","            ReLU-103          [32, 256, 14, 14]               0\n","          Conv2d-104          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [32, 256, 14, 14]             512\n","            ReLU-106          [32, 256, 14, 14]               0\n","          Conv2d-107         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [32, 1024, 14, 14]           2,048\n","            ReLU-109         [32, 1024, 14, 14]               0\n","      Bottleneck-110         [32, 1024, 14, 14]               0\n","          Conv2d-111          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [32, 256, 14, 14]             512\n","            ReLU-113          [32, 256, 14, 14]               0\n","          Conv2d-114          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [32, 256, 14, 14]             512\n","            ReLU-116          [32, 256, 14, 14]               0\n","          Conv2d-117         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [32, 1024, 14, 14]           2,048\n","            ReLU-119         [32, 1024, 14, 14]               0\n","      Bottleneck-120         [32, 1024, 14, 14]               0\n","          Conv2d-121          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [32, 256, 14, 14]             512\n","            ReLU-123          [32, 256, 14, 14]               0\n","          Conv2d-124          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [32, 256, 14, 14]             512\n","            ReLU-126          [32, 256, 14, 14]               0\n","          Conv2d-127         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [32, 1024, 14, 14]           2,048\n","            ReLU-129         [32, 1024, 14, 14]               0\n","      Bottleneck-130         [32, 1024, 14, 14]               0\n","          Conv2d-131          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [32, 256, 14, 14]             512\n","            ReLU-133          [32, 256, 14, 14]               0\n","          Conv2d-134          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [32, 256, 14, 14]             512\n","            ReLU-136          [32, 256, 14, 14]               0\n","          Conv2d-137         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [32, 1024, 14, 14]           2,048\n","            ReLU-139         [32, 1024, 14, 14]               0\n","      Bottleneck-140         [32, 1024, 14, 14]               0\n","          Conv2d-141          [32, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [32, 512, 14, 14]           1,024\n","            ReLU-143          [32, 512, 14, 14]               0\n","          Conv2d-144            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [32, 512, 7, 7]           1,024\n","            ReLU-146            [32, 512, 7, 7]               0\n","          Conv2d-147           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [32, 2048, 7, 7]           4,096\n","          Conv2d-149           [32, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [32, 2048, 7, 7]           4,096\n","            ReLU-151           [32, 2048, 7, 7]               0\n","      Bottleneck-152           [32, 2048, 7, 7]               0\n","          Conv2d-153            [32, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [32, 512, 7, 7]           1,024\n","            ReLU-155            [32, 512, 7, 7]               0\n","          Conv2d-156            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [32, 512, 7, 7]           1,024\n","            ReLU-158            [32, 512, 7, 7]               0\n","          Conv2d-159           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [32, 2048, 7, 7]           4,096\n","            ReLU-161           [32, 2048, 7, 7]               0\n","      Bottleneck-162           [32, 2048, 7, 7]               0\n","          Conv2d-163            [32, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [32, 512, 7, 7]           1,024\n","            ReLU-165            [32, 512, 7, 7]               0\n","          Conv2d-166            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [32, 512, 7, 7]           1,024\n","            ReLU-168            [32, 512, 7, 7]               0\n","          Conv2d-169           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [32, 2048, 7, 7]           4,096\n","            ReLU-171           [32, 2048, 7, 7]               0\n","      Bottleneck-172           [32, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [32, 2048, 1, 1]               0\n","          Linear-174                  [32, 100]         204,900\n","================================================================\n","Total params: 23,712,932\n","Trainable params: 23,712,932\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 18.38\n","Forward/backward pass size (MB): 9169.65\n","Params size (MB): 90.46\n","Estimated Total Size (MB): 9278.48\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["#마지막 Linear layer의 softmax가 1000-d로 구성되어 있음 _ ImageNet Classification에 적합한 모델\n","#Cifar-100은 100개의 label이기 때문에 100-d로 linear layer 수정\n","for name, child in model.named_children():\n","    if isinstance(child, nn.Linear):\n","        model._modules[name]=nn.Linear(2048, 100).to(device) #instance 변경 후 device에 올리기\n","    elif isinstance(child, nn.Sequential): #sequential 안에 있으면 거기에서 변환\n","        for sname, schild in child.named_children():\n","            if isinstance(schild, nn.Linear):\n","                print(name,sname)\n","                model._modules[name]._modules[sname]=nn.Linear(2048, 100).to(device)"],"metadata":{"id":"hU7maA9_4Lgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["summary(model, (3,224,224), batch_size=32) #100-d로 변환 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UU9zHCno4Zmt","outputId":"737684e5-f004-440a-fa5e-c338559a4cb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [32, 64, 112, 112]           9,408\n","       BatchNorm2d-2         [32, 64, 112, 112]             128\n","              ReLU-3         [32, 64, 112, 112]               0\n","         MaxPool2d-4           [32, 64, 56, 56]               0\n","            Conv2d-5           [32, 64, 56, 56]           4,096\n","       BatchNorm2d-6           [32, 64, 56, 56]             128\n","              ReLU-7           [32, 64, 56, 56]               0\n","            Conv2d-8           [32, 64, 56, 56]          36,864\n","       BatchNorm2d-9           [32, 64, 56, 56]             128\n","             ReLU-10           [32, 64, 56, 56]               0\n","           Conv2d-11          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-12          [32, 256, 56, 56]             512\n","           Conv2d-13          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-14          [32, 256, 56, 56]             512\n","             ReLU-15          [32, 256, 56, 56]               0\n","       Bottleneck-16          [32, 256, 56, 56]               0\n","           Conv2d-17           [32, 64, 56, 56]          16,384\n","      BatchNorm2d-18           [32, 64, 56, 56]             128\n","             ReLU-19           [32, 64, 56, 56]               0\n","           Conv2d-20           [32, 64, 56, 56]          36,864\n","      BatchNorm2d-21           [32, 64, 56, 56]             128\n","             ReLU-22           [32, 64, 56, 56]               0\n","           Conv2d-23          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-24          [32, 256, 56, 56]             512\n","             ReLU-25          [32, 256, 56, 56]               0\n","       Bottleneck-26          [32, 256, 56, 56]               0\n","           Conv2d-27           [32, 64, 56, 56]          16,384\n","      BatchNorm2d-28           [32, 64, 56, 56]             128\n","             ReLU-29           [32, 64, 56, 56]               0\n","           Conv2d-30           [32, 64, 56, 56]          36,864\n","      BatchNorm2d-31           [32, 64, 56, 56]             128\n","             ReLU-32           [32, 64, 56, 56]               0\n","           Conv2d-33          [32, 256, 56, 56]          16,384\n","      BatchNorm2d-34          [32, 256, 56, 56]             512\n","             ReLU-35          [32, 256, 56, 56]               0\n","       Bottleneck-36          [32, 256, 56, 56]               0\n","           Conv2d-37          [32, 128, 56, 56]          32,768\n","      BatchNorm2d-38          [32, 128, 56, 56]             256\n","             ReLU-39          [32, 128, 56, 56]               0\n","           Conv2d-40          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-41          [32, 128, 28, 28]             256\n","             ReLU-42          [32, 128, 28, 28]               0\n","           Conv2d-43          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-44          [32, 512, 28, 28]           1,024\n","           Conv2d-45          [32, 512, 28, 28]         131,072\n","      BatchNorm2d-46          [32, 512, 28, 28]           1,024\n","             ReLU-47          [32, 512, 28, 28]               0\n","       Bottleneck-48          [32, 512, 28, 28]               0\n","           Conv2d-49          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-50          [32, 128, 28, 28]             256\n","             ReLU-51          [32, 128, 28, 28]               0\n","           Conv2d-52          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-53          [32, 128, 28, 28]             256\n","             ReLU-54          [32, 128, 28, 28]               0\n","           Conv2d-55          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-56          [32, 512, 28, 28]           1,024\n","             ReLU-57          [32, 512, 28, 28]               0\n","       Bottleneck-58          [32, 512, 28, 28]               0\n","           Conv2d-59          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-60          [32, 128, 28, 28]             256\n","             ReLU-61          [32, 128, 28, 28]               0\n","           Conv2d-62          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-63          [32, 128, 28, 28]             256\n","             ReLU-64          [32, 128, 28, 28]               0\n","           Conv2d-65          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-66          [32, 512, 28, 28]           1,024\n","             ReLU-67          [32, 512, 28, 28]               0\n","       Bottleneck-68          [32, 512, 28, 28]               0\n","           Conv2d-69          [32, 128, 28, 28]          65,536\n","      BatchNorm2d-70          [32, 128, 28, 28]             256\n","             ReLU-71          [32, 128, 28, 28]               0\n","           Conv2d-72          [32, 128, 28, 28]         147,456\n","      BatchNorm2d-73          [32, 128, 28, 28]             256\n","             ReLU-74          [32, 128, 28, 28]               0\n","           Conv2d-75          [32, 512, 28, 28]          65,536\n","      BatchNorm2d-76          [32, 512, 28, 28]           1,024\n","             ReLU-77          [32, 512, 28, 28]               0\n","       Bottleneck-78          [32, 512, 28, 28]               0\n","           Conv2d-79          [32, 256, 28, 28]         131,072\n","      BatchNorm2d-80          [32, 256, 28, 28]             512\n","             ReLU-81          [32, 256, 28, 28]               0\n","           Conv2d-82          [32, 256, 14, 14]         589,824\n","      BatchNorm2d-83          [32, 256, 14, 14]             512\n","             ReLU-84          [32, 256, 14, 14]               0\n","           Conv2d-85         [32, 1024, 14, 14]         262,144\n","      BatchNorm2d-86         [32, 1024, 14, 14]           2,048\n","           Conv2d-87         [32, 1024, 14, 14]         524,288\n","      BatchNorm2d-88         [32, 1024, 14, 14]           2,048\n","             ReLU-89         [32, 1024, 14, 14]               0\n","       Bottleneck-90         [32, 1024, 14, 14]               0\n","           Conv2d-91          [32, 256, 14, 14]         262,144\n","      BatchNorm2d-92          [32, 256, 14, 14]             512\n","             ReLU-93          [32, 256, 14, 14]               0\n","           Conv2d-94          [32, 256, 14, 14]         589,824\n","      BatchNorm2d-95          [32, 256, 14, 14]             512\n","             ReLU-96          [32, 256, 14, 14]               0\n","           Conv2d-97         [32, 1024, 14, 14]         262,144\n","      BatchNorm2d-98         [32, 1024, 14, 14]           2,048\n","             ReLU-99         [32, 1024, 14, 14]               0\n","      Bottleneck-100         [32, 1024, 14, 14]               0\n","          Conv2d-101          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-102          [32, 256, 14, 14]             512\n","            ReLU-103          [32, 256, 14, 14]               0\n","          Conv2d-104          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-105          [32, 256, 14, 14]             512\n","            ReLU-106          [32, 256, 14, 14]               0\n","          Conv2d-107         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-108         [32, 1024, 14, 14]           2,048\n","            ReLU-109         [32, 1024, 14, 14]               0\n","      Bottleneck-110         [32, 1024, 14, 14]               0\n","          Conv2d-111          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-112          [32, 256, 14, 14]             512\n","            ReLU-113          [32, 256, 14, 14]               0\n","          Conv2d-114          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-115          [32, 256, 14, 14]             512\n","            ReLU-116          [32, 256, 14, 14]               0\n","          Conv2d-117         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-118         [32, 1024, 14, 14]           2,048\n","            ReLU-119         [32, 1024, 14, 14]               0\n","      Bottleneck-120         [32, 1024, 14, 14]               0\n","          Conv2d-121          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-122          [32, 256, 14, 14]             512\n","            ReLU-123          [32, 256, 14, 14]               0\n","          Conv2d-124          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-125          [32, 256, 14, 14]             512\n","            ReLU-126          [32, 256, 14, 14]               0\n","          Conv2d-127         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-128         [32, 1024, 14, 14]           2,048\n","            ReLU-129         [32, 1024, 14, 14]               0\n","      Bottleneck-130         [32, 1024, 14, 14]               0\n","          Conv2d-131          [32, 256, 14, 14]         262,144\n","     BatchNorm2d-132          [32, 256, 14, 14]             512\n","            ReLU-133          [32, 256, 14, 14]               0\n","          Conv2d-134          [32, 256, 14, 14]         589,824\n","     BatchNorm2d-135          [32, 256, 14, 14]             512\n","            ReLU-136          [32, 256, 14, 14]               0\n","          Conv2d-137         [32, 1024, 14, 14]         262,144\n","     BatchNorm2d-138         [32, 1024, 14, 14]           2,048\n","            ReLU-139         [32, 1024, 14, 14]               0\n","      Bottleneck-140         [32, 1024, 14, 14]               0\n","          Conv2d-141          [32, 512, 14, 14]         524,288\n","     BatchNorm2d-142          [32, 512, 14, 14]           1,024\n","            ReLU-143          [32, 512, 14, 14]               0\n","          Conv2d-144            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-145            [32, 512, 7, 7]           1,024\n","            ReLU-146            [32, 512, 7, 7]               0\n","          Conv2d-147           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-148           [32, 2048, 7, 7]           4,096\n","          Conv2d-149           [32, 2048, 7, 7]       2,097,152\n","     BatchNorm2d-150           [32, 2048, 7, 7]           4,096\n","            ReLU-151           [32, 2048, 7, 7]               0\n","      Bottleneck-152           [32, 2048, 7, 7]               0\n","          Conv2d-153            [32, 512, 7, 7]       1,048,576\n","     BatchNorm2d-154            [32, 512, 7, 7]           1,024\n","            ReLU-155            [32, 512, 7, 7]               0\n","          Conv2d-156            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-157            [32, 512, 7, 7]           1,024\n","            ReLU-158            [32, 512, 7, 7]               0\n","          Conv2d-159           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-160           [32, 2048, 7, 7]           4,096\n","            ReLU-161           [32, 2048, 7, 7]               0\n","      Bottleneck-162           [32, 2048, 7, 7]               0\n","          Conv2d-163            [32, 512, 7, 7]       1,048,576\n","     BatchNorm2d-164            [32, 512, 7, 7]           1,024\n","            ReLU-165            [32, 512, 7, 7]               0\n","          Conv2d-166            [32, 512, 7, 7]       2,359,296\n","     BatchNorm2d-167            [32, 512, 7, 7]           1,024\n","            ReLU-168            [32, 512, 7, 7]               0\n","          Conv2d-169           [32, 2048, 7, 7]       1,048,576\n","     BatchNorm2d-170           [32, 2048, 7, 7]           4,096\n","            ReLU-171           [32, 2048, 7, 7]               0\n","      Bottleneck-172           [32, 2048, 7, 7]               0\n","AdaptiveAvgPool2d-173           [32, 2048, 1, 1]               0\n","          Linear-174                  [32, 100]         204,900\n","================================================================\n","Total params: 23,712,932\n","Trainable params: 23,712,932\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 18.38\n","Forward/backward pass size (MB): 9169.65\n","Params size (MB): 90.46\n","Estimated Total Size (MB): 9278.48\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer,epochs,max_lr,grad_clip=None):\n","  size = len(dataloader.dataset)\n","  sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n","                                                steps_per_epoch=len(dataloader))\n","  lrs=[]\n","  model.train()\n","  for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        pred = model(X)\n","        loss = loss_fn(pred, y)\n","\n","        if grad_clip: #gradient clipping\n","                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        lrs.append(get_lr(optimizer))\n","        sched.step()\n","\n","        if batch % 100 == 0:\n","            loss, current = loss.item(), batch * len(X)\n","            print(loss)\n","\n","def test(dataloader, model, loss_fn):\n","  \n","  size=len(dataloader.dataset)\n","  num_batches=len(dataloader)\n","  model.eval()\n","  loss, correct=0,0\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y=X.to(device), y.to(device)\n","      pred=model(X)\n","      loss+=loss_fn(pred,y).item()\n","      correct+=(pred.argmax(1)==y).type(torch.float).sum().item()\n","  loss/=num_batches\n","  correct/=size\n","  print('accuracy:'+str(100*correct), 'loss:' +str(loss))\n","\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']"],"metadata":{"id":"pLWz4Nj58E0T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epoch = 20 #20 Epoch에 정확도 61% 수준,, \n","for t in range(epoch):\n","\n","  print('epoch('+str(t+1)+'/'+str(epoch)+')')\n","  train(train_db, model, loss_fn, optimizer,epoch, 0.01)\n","  test(test_db, model, loss_fn)\n","  \n","print('done!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hFlTrHMy8H7M","outputId":"9e5b7c61-aa02-4950-a491-9f136a5b126e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch(1/20)\n","4.615495681762695\n","4.376228332519531\n","3.343193292617798\n","3.0038888454437256\n","3.0677719116210938\n","2.8942923545837402\n","2.7303531169891357\n","3.1208972930908203\n","3.1054129600524902\n","2.762056350708008\n","3.0382602214813232\n","3.472717761993408\n","2.252007007598877\n","2.7657196521759033\n","2.933149576187134\n","3.0089261531829834\n","accuracy:36.78 loss:2.5490293632300136\n","epoch(2/20)\n","2.3823137283325195\n","2.423600435256958\n","2.208503246307373\n","2.263887882232666\n","2.4532291889190674\n","1.533050775527954\n","2.629459857940674\n","2.5157315731048584\n","2.5312321186065674\n","2.559492588043213\n","1.6848491430282593\n","2.600003719329834\n","2.5988986492156982\n","2.4901270866394043\n","3.0182278156280518\n","2.290137767791748\n","accuracy:39.54 loss:2.439271952016666\n","epoch(3/20)\n","2.224228858947754\n","2.2281625270843506\n","2.099073648452759\n","2.201167106628418\n","2.2201578617095947\n","1.859486699104309\n","1.9062190055847168\n","1.7283892631530762\n","1.8501701354980469\n","2.7545695304870605\n","2.237600564956665\n","2.3745172023773193\n","2.3602795600891113\n","2.871743679046631\n","3.0025010108947754\n","1.9429994821548462\n","accuracy:40.5 loss:2.368562074134144\n","epoch(4/20)\n","2.855541229248047\n","1.7348778247833252\n","1.986913800239563\n","1.708780288696289\n","1.943291425704956\n","1.5149223804473877\n","2.041292428970337\n","1.8811759948730469\n","2.197421073913574\n","2.7835195064544678\n","1.9422272443771362\n","1.7053325176239014\n","2.11541485786438\n","2.4413769245147705\n","2.812018632888794\n","2.0106661319732666\n","accuracy:41.980000000000004 loss:2.2734769053352526\n","epoch(5/20)\n","2.207261085510254\n","1.8625801801681519\n","2.2339508533477783\n","1.8425315618515015\n","2.098937511444092\n","2.2426156997680664\n","1.752704381942749\n","2.258552312850952\n","2.0413336753845215\n","1.9281049966812134\n","2.157921075820923\n","2.205125331878662\n","2.472829580307007\n","1.9454593658447266\n","2.5657520294189453\n","2.0988054275512695\n","accuracy:46.89 loss:2.1059492057123883\n","epoch(6/20)\n","2.1526925563812256\n","2.3109328746795654\n","1.9948248863220215\n","2.451653242111206\n","1.7286949157714844\n","1.9157984256744385\n","1.2907058000564575\n","2.4773647785186768\n","1.967098355293274\n","2.252457618713379\n","1.6800556182861328\n","1.9789347648620605\n","1.9757132530212402\n","1.653742790222168\n","1.9054267406463623\n","1.9284933805465698\n","accuracy:48.41 loss:2.014692161029901\n","epoch(7/20)\n","2.552659034729004\n","2.4299542903900146\n","1.8939619064331055\n","1.3848259449005127\n","1.5961103439331055\n","2.0972938537597656\n","1.9766619205474854\n","2.2203657627105713\n","2.2589142322540283\n","1.8410148620605469\n","1.9340331554412842\n","1.5914456844329834\n","2.2287819385528564\n","2.215834140777588\n","2.3844854831695557\n","2.37801456451416\n","accuracy:50.0 loss:1.971849748120902\n","epoch(8/20)\n","2.111314058303833\n","1.488059401512146\n","1.8320552110671997\n","2.4236016273498535\n","1.628625512123108\n","1.55997896194458\n","2.280048370361328\n","2.080353021621704\n","1.883703589439392\n","1.7149056196212769\n","1.448932409286499\n","2.05411434173584\n","1.9463456869125366\n","1.9491350650787354\n","2.072334051132202\n","2.269547700881958\n","accuracy:51.67 loss:1.8790252684785154\n","epoch(9/20)\n","2.0542004108428955\n","2.132127046585083\n","1.471649408340454\n","1.6442513465881348\n","1.4529279470443726\n","2.028696060180664\n","1.6548634767532349\n","2.0850462913513184\n","1.9010339975357056\n","2.140617609024048\n","1.868816614151001\n","1.9981744289398193\n","1.7193139791488647\n","2.2428178787231445\n","1.914794683456421\n","1.9530823230743408\n","accuracy:53.02 loss:1.8466607549320013\n","epoch(10/20)\n","1.9940024614334106\n","1.888357400894165\n","1.485741376876831\n","1.0119560956954956\n","1.2743771076202393\n","1.5253167152404785\n","1.6959691047668457\n","1.6654036045074463\n","1.5731083154678345\n","2.1837363243103027\n","1.7976988554000854\n","1.2814288139343262\n","1.4788559675216675\n","1.793055534362793\n","1.9395220279693604\n","1.6162605285644531\n","accuracy:53.72 loss:1.79149770355834\n","epoch(11/20)\n","1.9733792543411255\n","1.8585985898971558\n","1.7608526945114136\n","1.2728188037872314\n","1.6268583536148071\n","1.9530047178268433\n","1.6240336894989014\n","1.6048915386199951\n","1.7085901498794556\n","1.3955895900726318\n","1.8126084804534912\n","1.5161793231964111\n","2.2091422080993652\n","1.4868115186691284\n","1.8742605447769165\n","1.942233920097351\n","accuracy:56.120000000000005 loss:1.7268591422242479\n","epoch(12/20)\n","1.8088878393173218\n","1.7074332237243652\n","1.654364824295044\n","1.5279474258422852\n","1.427123785018921\n","1.0951833724975586\n","1.5738786458969116\n","1.8005520105361938\n","1.4805916547775269\n","1.2964295148849487\n","1.6189066171646118\n","1.9617750644683838\n","1.865372657775879\n","1.4992212057113647\n","2.1327295303344727\n","1.590216040611267\n","accuracy:56.86 loss:1.6644268843312613\n","epoch(13/20)\n","1.6099138259887695\n","1.808521032333374\n","1.2675656080245972\n","1.6434664726257324\n","1.5941489934921265\n","1.740057349205017\n","1.3805584907531738\n","1.589726448059082\n","1.0895472764968872\n","1.5988006591796875\n","1.3587034940719604\n","1.6336528062820435\n","1.5154731273651123\n","2.008894205093384\n","1.5445014238357544\n","2.178219795227051\n","accuracy:56.68 loss:1.6999110398581996\n","epoch(14/20)\n","1.6543197631835938\n","1.1450273990631104\n","1.7620919942855835\n","1.3618838787078857\n","1.320246934890747\n","1.622493863105774\n","1.3794881105422974\n","1.1916897296905518\n","1.4395389556884766\n","1.744241714477539\n","1.318670630455017\n","1.1151214838027954\n","1.6105908155441284\n","1.823549747467041\n","2.023367404937744\n","1.9007697105407715\n","accuracy:56.910000000000004 loss:1.6848845219078916\n","epoch(15/20)\n","1.7471328973770142\n","1.265297532081604\n","1.2282439470291138\n","1.0500109195709229\n","1.508636713027954\n","1.8251947164535522\n","1.3864948749542236\n","1.5530781745910645\n","1.2970670461654663\n","1.7522052526474\n","1.2220159769058228\n","1.768107295036316\n","1.7892000675201416\n","2.0192179679870605\n","1.5028003454208374\n","0.9429417252540588\n","accuracy:57.31 loss:1.6686706874317254\n","epoch(16/20)\n","1.6037639379501343\n","1.3132622241973877\n","1.8231000900268555\n","1.4692384004592896\n","1.0668818950653076\n","1.4279662370681763\n","1.7076656818389893\n","0.9277599453926086\n","1.6117298603057861\n","1.3770314455032349\n","1.6500389575958252\n","1.6018736362457275\n","1.818623423576355\n","1.742618203163147\n","1.9931766986846924\n","1.5376176834106445\n","accuracy:59.150000000000006 loss:1.5864598880560634\n","epoch(17/20)\n","1.6766858100891113\n","1.5150902271270752\n","1.668839454650879\n","1.6942963600158691\n","1.7465708255767822\n","0.9817440509796143\n","1.2628884315490723\n","1.6506435871124268\n","1.3911948204040527\n","1.7026050090789795\n","1.0226181745529175\n","1.7258634567260742\n","1.321455717086792\n","2.2428526878356934\n","1.0092523097991943\n","1.7763042449951172\n","accuracy:60.47 loss:1.544215509304985\n","epoch(18/20)\n","1.7500526905059814\n","1.450964093208313\n","1.048156499862671\n","1.8640098571777344\n","1.4312909841537476\n","1.3655844926834106\n","1.392220377922058\n","1.6228114366531372\n","1.4608137607574463\n","1.6656012535095215\n","1.3310242891311646\n","1.671126365661621\n","1.1750000715255737\n","2.5368473529815674\n","1.720243215560913\n","1.2737126350402832\n","accuracy:58.550000000000004 loss:1.5982683390474166\n","epoch(19/20)\n","1.789236068725586\n","0.7934487462043762\n","1.0928202867507935\n","1.445289134979248\n","0.8921941518783569\n","1.4588768482208252\n","1.3198051452636719\n","1.2520751953125\n","1.3137634992599487\n","1.9183987379074097\n","1.334098219871521\n","1.9189503192901611\n","1.3224974870681763\n","1.6321851015090942\n","2.102367639541626\n","1.7960960865020752\n","accuracy:61.44 loss:1.4734377967663848\n","epoch(20/20)\n","1.0385727882385254\n","1.1948555707931519\n","0.9283813238143921\n","1.32077157497406\n","1.2313741445541382\n","1.1043157577514648\n","1.2432475090026855\n","1.5167068243026733\n","1.8013081550598145\n","1.3316060304641724\n","0.7261907458305359\n","1.621702790260315\n","1.2083066701889038\n","1.7957621812820435\n","1.9033763408660889\n","1.3156479597091675\n","accuracy:60.57 loss:1.5218736144681326\n","done!\n"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}