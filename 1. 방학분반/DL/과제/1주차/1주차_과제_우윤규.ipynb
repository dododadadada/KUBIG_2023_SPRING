{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YffDGVSIxijw"
   },
   "source": [
    "#1주차 과제\n",
    "- 파이토치 시작하기 및 간단한 코드 빈칸 채워넣기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MivAstLj4EpN"
   },
   "source": [
    "#파이토치 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE4yLA7N4TwG"
   },
   "source": [
    "파이토치 시작하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BS39ZJTi4CD0"
   },
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixz0WyWH4kSJ"
   },
   "source": [
    "- tensor 개념 파악 (array of numerical values(vector, matrix..))\n",
    "- 4x3 행렬 두개 만들고 행으로 병합, 열로 병합\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OlLUsvmL4kEY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((4,3))\n",
    "Y = torch.zeros((4,3))\n",
    "\n",
    "###행으로 병합 코드\n",
    "torch.cat((X,Y), dim = 0)\n",
    "\n",
    "###열로 병합 코드\n",
    "torch.cat((X,Y), dim = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh-1LJliusEc"
   },
   "source": [
    "linear regression implementation from scratch\n",
    "- 머신러닝 기초와 비슷한 내용이지만 파이토치로 실행해보며 익숙해지는것이 목표\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ybbbqg8TqAVR"
   },
   "outputs": [],
   "source": [
    "# !pip install d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YyWEB6e3FKYY"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "exWjbVn2v3CT"
   },
   "outputs": [],
   "source": [
    "def synthetic_data(w, b, num_examples):\n",
    "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([3, -1.5])\n",
    "true_b = 5.5\n",
    "features, labels = synthetic_data(true_w, true_b, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5UcjckXPv6iy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([-0.4943,  0.0110]) \n",
      "label: tensor([3.9953])\n"
     ]
    }
   ],
   "source": [
    "print('features:', features[0],'\\nlabel:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jLY6YR5Zv_gO"
   },
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # The examples are read at random, in no particular order\n",
    "    random.shuffle(indices)\n",
    "     ###반복문으로 채워넣기:\n",
    "        ##이하는 반복문에 대한 조건입니다.\n",
    "    for i in range(math.ceil(num_examples / batch_size)):\n",
    "        batch_indices = torch.tensor(indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zuxxEAvdwA7p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4020, -0.0354],\n",
      "        [ 1.5937, -0.7750]]) \n",
      " tensor([[ 6.7650],\n",
      "        [11.4407]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "f_yHcVYEwCHq"
   },
   "outputs": [],
   "source": [
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.Tensor(3 )#원하는 실수를 넣어주세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wOT4gBtZwDVA"
   },
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    \"\"\"The linear regression model.\"\"\"\n",
    "    y = torch.matmul(X, w) + b\n",
    "    return y\n",
    "     ###lr func 코드 완성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Using a target size (torch.Size([2, 1])) that is different to the input size (torch.Size([2, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(inf, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "WFYMJrrSwE5R"
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y):  \n",
    "    \"\"\"Squared loss.\"\"\"\n",
    "    diff = torch.sqrt((y_hat - y) ** 2)\n",
    "    return diff###loss function 직접 짜보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "MXD0qP8PwIn0"
   },
   "outputs": [],
   "source": [
    "# def sgd(params, lr, batch_size):\n",
    "#     \"\"\"Minibatch stochastic gradient descent.\"\"\"\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for idx in range(batch_size):\n",
    "           \n",
    "#             part = torch.zeros(params.shape)\n",
    "\n",
    "#             params = params - 2 * lr * l * 1\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "#     return loss(net(X, w, b), y)\n",
    "\n",
    "#         ###반복문으로 채워넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "net = deepcopy(linreg)\n",
    "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
    "b = torch.Tensor(3 )#원하는 실수를 넣어주세요a\n",
    "b.requires_grad_(True)\n",
    "\n",
    "z = net(X, w, b)\n",
    "\n",
    "batch_size = 2\n",
    "lr = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "\n",
    "loss_fun = squared_loss\n",
    "loss = loss_fun(net(X, w, b), y)\n",
    "loss.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "pS_hm3J8wJ4z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss inf\n",
      "epoch 2, loss inf\n",
      "epoch 3, loss inf\n",
      "epoch 4, loss inf\n",
      "epoch 5, loss inf\n",
      "epoch 6, loss inf\n",
      "epoch 7, loss inf\n",
      "epoch 8, loss inf\n",
      "epoch 9, loss inf\n",
      "epoch 10, loss inf\n",
      "epoch 11, loss inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-7e28a8ba4e5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# Compute gradient on `l` with respect to [`w`, `b`]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-50543730e675>\u001b[0m in \u001b[0;36msquared_loss\u001b[1;34m(y_hat, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msquared_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m\"\"\"Squared loss.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;31m###loss function 직접 짜보기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "\n",
    "        w = w - lr * w.grad\n",
    "        b = b - lr * b.grad\n",
    "        w.detach_().requires_grad_(True)\n",
    "        b.detach_().requires_grad_(True)\n",
    "\n",
    "        z = net(X, w, b)\n",
    "        loss = loss_fun(z, y)\n",
    "        # Compute gradient on `l` with respect to [`w`, `b`]\n",
    "        loss.mean().backward()\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        train_l = loss_fun(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_WSAjwNwMEY"
   },
   "outputs": [],
   "source": [
    "print(f'error in estimating w: {true_w - w.reshape(true_w.shape)}')\n",
    "print(f'error in estimating b: {true_b - b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDSteRKdREC9"
   },
   "source": [
    "+cost graph 그리기 (x축 w, y축 loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13ySyXh7RMcn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSKKAGx4wNd4"
   },
   "source": [
    "concise implementation of linear regression \n",
    "- api 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "CWiOlkzKxEkf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "true_w = torch.tensor([3, -1.5])\n",
    "true_b = 5.5\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "F5tRyjkmxGUe"
   },
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True): \n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 20\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "NBaqnZG4xHgP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-1.4734,  0.6347],\n",
       "         [-1.5959, -1.4912],\n",
       "         [ 1.0237,  2.4512],\n",
       "         [ 0.2395,  0.3285],\n",
       "         [-0.6422,  0.1363],\n",
       "         [-1.2340, -0.9216],\n",
       "         [ 0.7048, -0.3399],\n",
       "         [ 1.8234,  1.1751],\n",
       "         [ 2.1104,  0.0038],\n",
       "         [-0.0412, -0.6555],\n",
       "         [-1.0069,  0.4127],\n",
       "         [ 2.5950, -0.4650],\n",
       "         [ 0.8614, -0.9055],\n",
       "         [-0.0716, -0.0112],\n",
       "         [-1.5657,  0.6340],\n",
       "         [ 2.2878,  1.1505],\n",
       "         [-0.7395, -0.5672],\n",
       "         [ 0.1311,  1.4754],\n",
       "         [ 0.5626,  1.0101],\n",
       "         [ 1.4147,  0.7226]]),\n",
       " tensor([[ 0.1164],\n",
       "         [ 2.9502],\n",
       "         [ 4.8995],\n",
       "         [ 5.7190],\n",
       "         [ 3.3681],\n",
       "         [ 3.1845],\n",
       "         [ 8.1150],\n",
       "         [ 9.2027],\n",
       "         [11.8098],\n",
       "         [ 6.3682],\n",
       "         [ 1.8595],\n",
       "         [13.9746],\n",
       "         [ 9.4610],\n",
       "         [ 5.3027],\n",
       "         [-0.1471],\n",
       "         [10.6279],\n",
       "         [ 4.1184],\n",
       "         [ 3.6828],\n",
       "         [ 5.6718],\n",
       "         [ 8.6709]])]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "J_83KBFOxJFB"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential( nn.Linear(in_features=features.dim(), out_features=labels.dim()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "AdJQQgFaxL2H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSCAFyfAxNAn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "_yee2wG1xOYW"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#api function으로 직접 설정\n",
    "\n",
    "loss_fun = nn.MSELoss()\n",
    "trainer = torch.optim.SGD(net.parameters(), lr =0.01)###api function으로 직접 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "5fAmW5bUxP9Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 42.081650\n",
      "epoch 2, loss 42.081650\n",
      "epoch 3, loss 42.081650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([2000, 1])) that is different to the input size (torch.Size([2000, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "\n",
    "        l = loss_fun(X,y)\n",
    "        trainer.zero_grad()\n",
    "        l.requires_grad_(True)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    l = loss(net(features), labels)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "JT8VD6GhxR5m"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-156-d922e4f64034>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-156-d922e4f64034>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    w = ###학습결과 w 구하는 식\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "w = ###학습결과 w 구하는 식\n",
    "print('error in estimating w:', true_w - w.reshape(true_w.shape))\n",
    "b = ###학습결과 b 구하는 식\n",
    "print('error in estimating b:', true_b - b)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1주차 과제.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
