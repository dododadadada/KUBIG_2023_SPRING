{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.datasets import load_breast_cancer, load_wine,load_digits\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = data.data\n",
    "output_ = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    183\n",
       "1    182\n",
       "5    182\n",
       "4    181\n",
       "6    181\n",
       "9    180\n",
       "7    179\n",
       "0    178\n",
       "2    177\n",
       "8    174\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(444)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1797"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(input_, output_, test_size = 0.3,\n",
    "                                                   random_state= 44, stratify=data.target,\n",
    "                                                   shuffle = True)\n",
    "\n",
    "\n",
    "# 전처리\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train) # scaling의 기준은 train data가 되어야 한다.\n",
    "\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor(x_train).to(device)\n",
    "y_train = torch.LongTensor(y_train).to(device) # 범주형 변수는 long tensor 형에 넣어주어야 함.\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.3422, -1.0883, -0.9071,  0.2616, -1.0165, -0.4055, -0.1283,\n",
      "        -0.0657, -0.6260, -1.8989,  0.5122, -0.8992, -1.3375, -0.4991, -0.1320,\n",
      "        -0.0282, -0.7223, -0.6714,  0.8649, -1.1559, -1.2475, -0.5516, -0.1038,\n",
      "        -0.0282, -0.7874, -0.1730,  0.6910, -0.3250, -0.9309, -0.6222, -0.0399,\n",
      "         0.0000, -0.6780,  0.8389,  1.0998,  0.4571,  0.9045,  0.3328,  0.0000,\n",
      "        -0.0489, -0.5294,  0.6252,  0.1166, -0.9032, -0.9095,  2.2006, -0.0949,\n",
      "        -0.0426, -0.4090, -0.0935,  0.2918, -0.8380,  0.5516,  1.5141, -0.2006,\n",
      "        -0.0282, -0.3021, -0.8937, -0.2499,  0.0346, -0.4551, -0.4970, -0.1888],\n",
      "       device='cuda:0')\n",
      "tensor(6, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset 객체를 만들기 위해서는.. 3가지가 필요하다.\n",
    "    # __init__, __len__, __getitem__; 호출할때마다 x,y를 slicing을 통해서 불러올 수 있다. (짝지어서)\n",
    "    # 이를 DataLoader 객체에 넣어서 batch_size 별로 빼낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.x_data = x_train\n",
    "        self.y_data = [[y] for y in y_train]\n",
    "        # 데이터 셋 전처리는 미리 위에서 진행함 \n",
    "        # (X,y가 텐서 형태로 들어가서 sklearn이랑 연동되는지, 오류가 날지 잘 모름.)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    # 데이터 셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.FloatTensor(self.x_data[idx]).to(device)\n",
    "        y = torch.LongTensor(self.y_data[idx]).to(device)\n",
    "        # 데이터 셋을 slicing을 통해서 가져오게 할 수 있음.\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], device='cuda:0')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(64, 512),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(512, 256),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(256,128),\n",
    "                    nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                    nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.Softmax()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(64, 512),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer3 = nn.Sequential(nn.Linear(256,128),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer4 = nn.Sequential(nn.Linear(128,64),\n",
    "                                  nn.ReLU()\n",
    "                                   )\n",
    "                                    \n",
    "        self.layer5 = nn.Sequential(nn.Linear(64, 10),\n",
    "                                  nn.Softmax()\n",
    "                                  )\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        output = self.layer1(x)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)\n",
    "        output = self.layer5(output)        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(layer):\n",
    "    if isinstance(layer, nn.Linear): # 존재시\n",
    "        torch.nn.init.xavier_uniform(layer.weight)\n",
    "        layer.bias.data.fill_(0.01)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer1): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.306436538696289\n",
      "10 1.6321520805358887\n",
      "20 1.5863136053085327\n",
      "30 1.5815954208374023\n",
      "40 1.5800851583480835\n",
      "50 1.5797655582427979\n",
      "60 1.579595923423767\n",
      "70 1.5794721841812134\n",
      "80 1.5771812200546265\n",
      "90 1.5788310766220093\n",
      "100 1.5784028768539429\n",
      "110 1.5775946378707886\n",
      "120 1.577304720878601\n",
      "130 1.5763479471206665\n",
      "140 1.5766716003417969\n",
      "150 1.5760215520858765\n",
      "160 1.575722098350525\n",
      "170 1.5756648778915405\n",
      "180 1.5755767822265625\n",
      "190 1.5754884481430054\n",
      "200 1.5746763944625854\n",
      "210 1.5937743186950684\n",
      "220 1.5904988050460815\n",
      "230 1.5738201141357422\n",
      "240 1.5763473510742188\n",
      "250 1.610373616218567\n",
      "260 1.582582950592041\n",
      "270 1.5814390182495117\n",
      "280 1.59133780002594\n",
      "290 1.6032140254974365\n",
      "300 1.5876303911209106\n",
      "310 1.6011143922805786\n",
      "320 1.6154457330703735\n",
      "330 1.6006097793579102\n",
      "340 1.6228156089782715\n",
      "350 1.669569730758667\n",
      "360 1.6325209140777588\n",
      "370 1.6035441160202026\n",
      "380 1.5971543788909912\n",
      "390 1.6011533737182617\n",
      "400 1.6345239877700806\n",
      "410 1.6124908924102783\n",
      "420 1.6520458459854126\n",
      "430 1.6513186693191528\n",
      "440 1.6544641256332397\n",
      "450 1.6433302164077759\n",
      "460 1.6130211353302002\n",
      "470 1.6091217994689941\n",
      "480 1.6035525798797607\n",
      "490 1.5955917835235596\n",
      "500 1.615459680557251\n",
      "510 1.6154855489730835\n",
      "520 1.631461262702942\n",
      "530 1.6306004524230957\n",
      "540 1.6345794200897217\n",
      "550 1.6361076831817627\n",
      "560 1.6266282796859741\n",
      "570 1.6401481628417969\n",
      "580 1.657341718673706\n",
      "590 1.6616281270980835\n",
      "600 1.642526626586914\n",
      "610 1.6441142559051514\n",
      "620 1.622597098350525\n",
      "630 1.610713005065918\n",
      "640 1.6799209117889404\n",
      "650 1.6671967506408691\n",
      "660 1.6504902839660645\n",
      "670 1.6476895809173584\n",
      "680 1.652066946029663\n",
      "690 1.6616278886795044\n",
      "700 1.7126227617263794\n",
      "710 1.718907117843628\n",
      "720 1.7212938070297241\n",
      "730 1.658440113067627\n",
      "740 1.6512857675552368\n",
      "750 1.664810061454773\n",
      "760 1.6990184783935547\n",
      "770 1.711747169494629\n",
      "780 1.7204982042312622\n",
      "790 1.724475383758545\n",
      "800 1.7332268953323364\n",
      "810 1.7037917375564575\n",
      "820 1.700609564781189\n",
      "830 1.690267562866211\n",
      "840 1.6886764764785767\n",
      "850 1.688667893409729\n",
      "860 1.689471960067749\n",
      "870 1.690267562866211\n",
      "880 1.689471960067749\n",
      "890 1.6791298389434814\n",
      "900 1.6664011478424072\n",
      "910 1.6647831201553345\n",
      "920 1.6568546295166016\n",
      "930 1.6481035947799683\n",
      "940 1.6512857675552368\n",
      "950 1.68231201171875\n",
      "960 1.7109686136245728\n",
      "970 1.6990184783935547\n",
      "980 1.6998140811920166\n",
      "990 1.7014051675796509\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(x_train)\n",
    "    \n",
    "    cost = loss_fn(hypothesis, y_train)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(cost.item())\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model = model.to('cpu') # 평가하려면 다시 cpu로 바꿔줘야 한다.\n",
    "    y_pred = model(x_test)\n",
    "    y_pred = y_pred.detach().numpy()\n",
    "    predicted = np.argmax(y_pred, axis = 1)\n",
    "    accuracy = (accuracy_score(predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  시도 1\n",
    "        self.layer1 = nn.Sequential(nn.Linear(64, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(512)\n",
    "                                  )\n",
    "        self.layer2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(256)\n",
    "                                  )\n",
    "        self.layer3 = nn.Sequential(nn.Linear(256,128),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(128)\n",
    "                                  )\n",
    "        self.layer4 = nn.Sequential(nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(64))\n",
    "                                    \n",
    "        self.layer5 = nn.Sequential(nn.Linear(64, 10),\n",
    "                                  nn.Softmax()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model의 output은 :  [1.1780186e-07 4.2356592e-07 9.9998474e-01 4.6215891e-06 7.4967488e-07\n",
      " 4.8543619e-08 9.9935244e-07 1.0347535e-06 3.2611381e-06 4.0163632e-06]\n",
      "argmax를 한 후의 output은 2\n",
      "accuracy는 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f'model의 output은 :  {y_pred[0]}')\n",
    "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
    "print(f'accuracy는 {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시도 2 \n",
    "        self.layer1 = nn.Sequential(nn.Linear(64, 512),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(512)\n",
    "                                  )\n",
    "        self.layer2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(256)\n",
    "                                  )\n",
    "        self.layer3 = nn.Sequential(nn.Linear(256,128),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(128)\n",
    "                                  )\n",
    "        self.layer4 = nn.Sequential(nn.Linear(128,64),\n",
    "                                  nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(64))\n",
    "                                    \n",
    "        self.layer5 = nn.Sequential(nn.Linear(64, 10),\n",
    "                                  nn.Softmax()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model의 output은 :  [1.9809778e-07 2.6678740e-07 9.9999559e-01 2.9670111e-06 4.0406394e-09\n",
      " 4.7841791e-08 9.8224533e-08 7.2619613e-08 7.1885671e-07 3.1498931e-08]\n",
      "argmax를 한 후의 output은 2\n",
      "accuracy는 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(f'model의 output은 :  {y_pred[0]}')\n",
    "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
    "print(f'accuracy는 {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시도 3\n",
    "\n",
    "\n",
    "        self.layer1 = nn.Sequential(nn.Linear(64, 512),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer2 = nn.Sequential(nn.Linear(512, 256),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer3 = nn.Sequential(nn.Linear(256,128),\n",
    "                                  nn.ReLU()\n",
    "                                  )\n",
    "        self.layer4 = nn.Sequential(nn.Linear(128,64),\n",
    "                                  nn.ReLU()\n",
    "                                   )\n",
    "                                    \n",
    "        self.layer5 = nn.Sequential(nn.Linear(64, 10),\n",
    "                                  nn.Softmax()\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model의 output은 :  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "argmax를 한 후의 output은 2\n",
      "accuracy는 0.7518518518518519\n"
     ]
    }
   ],
   "source": [
    "print(f'model의 output은 :  {y_pred[0]}')\n",
    "print(f'argmax를 한 후의 output은 {predicted[0]}')\n",
    "print(f'accuracy는 {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "- layer 수를 직접 계산해서 넣어야 한다 (이어지는 게 아니라, 공식으로 계산해야한다)\n",
    "- 맨 마지막은 flatten 시켜서 linear로 보아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size = 28, scale = (0.5, 1.0)), # 중간 기준 일부분만 잘라냄. (여기서는 그냥 정의만 함. )\n",
    "    transforms.RandomHorizontalFlip(), # 옆으로 뒤집기\n",
    "    transforms.RandomVerticalFlip(), # 위아래 뒤집기\n",
    "    transforms.RandomRotation(10), # -10 ~ +10 도 기울기\n",
    "    transforms.ToTensor() # 텐서로 변환 (이미지는 array, 텐서로 변환)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist_train), len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc = nn.Linear(320,10)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = x.view(in_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_model = Net().to(device)\n",
    "# test_model(mnist_test.data[0].type(torch.float32).view(-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = Variable(data).to(device), Variable(target).to(device) \n",
    "        # 앞으로 이거를 통해서 grad, data, grad_fn(backward후 미분)를 계산 및 보겠다\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "              100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval() \n",
    "    # evaluation 과정에서 사용하지 않을 layer들을 수행하지 않음.\n",
    "    # 학습할 때만 필요한 Dropout, BatchNorm layer 등을 수행하지 않음.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():# model안의 Variable들의 gradient 추적 중단 및 업데이트 중단\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data, volatile = True).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average= False).data\n",
    "            # nll_loss + log_softmax = Cross entorpy (cross entropy시에는 softmax를 마지막 layer에 사용)\n",
    "            pred = output.data.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.289888\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.293001\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.262386\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.261545\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.248804\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.213537\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.209642\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.180830\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.131850\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.073099\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.979782\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.729370\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.579321\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.359909\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.004479\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.948271\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.751223\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.738187\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.787225\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.686653\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.682088\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.607565\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.557571\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.533781\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.499586\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.476641\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.252562\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.423787\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.360794\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.361362\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.676867\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.557796\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.444927\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.435712\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.380579\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.388095\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.285842\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.468943\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.367478\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.358839\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.424054\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.300633\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.270173\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.301437\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.230654\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.284067\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.617321\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.297590\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.206558\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.379847\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.434219\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.191053\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.259841\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.357813\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.312245\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.161147\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.340636\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.247309\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.173073\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.126866\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.279849\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.330421\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.250963\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.248185\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.246527\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.186246\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.211523\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.151762\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.146526\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.225955\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.320963\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.356440\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.414566\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.154274\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.298871\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.191226\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.315836\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.233177\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.320755\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.634555\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.271725\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.191898\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.087021\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.499902\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.234204\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.293549\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.129158\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.156950\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.224912\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.263050\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.156303\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.287894\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.202936\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.177569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.1961, Accuracy: 9434/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.111977\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.216360\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.513448\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.223371\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.120169\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.249799\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.251036\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.256873\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.189647\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.297765\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.236799\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.084871\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.183384\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.191140\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.051463\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.107607\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.046159\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.092471\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.134572\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.202003\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.096536\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.265588\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.120936\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.099118\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.140114\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.161677\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.128336\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.162713\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.210362\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.127260\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.292169\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.142386\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.118882\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.208383\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.279434\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.338812\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.151875\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.231092\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.110673\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.312908\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.111465\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.240671\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.206135\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.078930\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.089305\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.405974\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.146002\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.238429\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.153297\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.209936\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.055030\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.088228\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.091595\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.128267\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.201673\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.135266\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.120379\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.231454\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.209973\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.137334\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.163459\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.080633\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.214361\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.195234\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.218758\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.130176\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.257536\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.071675\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.192699\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.096972\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.148753\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.097502\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.130334\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.145663\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.128153\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.205506\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.199736\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.110316\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.083338\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.221229\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.142385\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.328943\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.076421\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.174688\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.071584\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.143190\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.071968\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.091551\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.153102\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.141689\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.153399\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.068982\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.067499\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.112173\n",
      "\n",
      "Test set: Average loss: 0.1138, Accuracy: 9662/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.090952\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.155315\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.091517\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.141056\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.116282\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.117679\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.068927\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.160197\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.017966\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.093018\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.058789\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.094119\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.076304\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.138748\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.048460\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.106770\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.218816\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.104004\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.148722\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.061110\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.017386\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.125607\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.131419\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.276978\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.205546\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.052079\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.072503\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.163057\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.259307\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.187847\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.114374\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.207053\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.283590\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.052293\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.134315\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.063103\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.072570\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.139075\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.055458\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.064455\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.114253\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.094108\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.099715\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.294967\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.056840\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.128705\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.128376\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.065100\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.124115\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.114612\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.052555\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.161484\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.204621\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.109213\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.101810\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.085865\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.155313\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.041554\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.236168\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.210232\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.129588\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.057914\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.123279\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.191247\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.161395\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.126460\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.215768\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.052000\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.040978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.049924\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.146769\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.169081\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.109875\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.111704\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.165090\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.093170\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.047881\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.044623\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.051995\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.239166\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.030570\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.061621\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.072167\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.041003\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.059609\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.120254\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.052565\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.258018\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.041101\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.220887\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.217125\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.120954\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.154750\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.112959\n",
      "\n",
      "Test set: Average loss: 0.0922, Accuracy: 9720/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.035388\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.128924\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.029905\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.227315\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.022676\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.069477\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.166266\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.089904\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.081029\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.046538\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.037475\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.118598\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.139239\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.086850\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.163214\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.053100\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.059293\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.094439\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.095425\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.064864\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.099297\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.152579\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.234663\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.113537\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.067784\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.057808\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.077196\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.126126\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.042041\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.121994\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.039201\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.165992\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.043424\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.050458\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.056388\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.057865\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.121563\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.022552\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.101126\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.085358\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.120142\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.059579\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.050931\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.143551\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.149631\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.033858\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.078698\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.062549\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.030083\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.079695\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.024799\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.285634\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.084554\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.081552\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.057442\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.163592\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.225582\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.101261\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.176369\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.024147\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.091456\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.094211\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.084034\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.058925\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.104575\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.014691\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.155738\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.107299\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.023450\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.060649\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.107142\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.339150\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.051578\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.086417\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.091779\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.055933\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.047003\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.136312\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.113157\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.079247\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.085754\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.053306\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.023726\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.162705\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.047099\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.129839\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.066778\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.122698\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.136322\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.058403\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.019922\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.084535\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.093336\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.167428\n",
      "\n",
      "Test set: Average loss: 0.0762, Accuracy: 9780/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.028521\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.052724\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.104333\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.086634\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.126551\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.057314\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.104191\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.022227\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.126370\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.030413\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.051707\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.051274\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.143081\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.158650\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.123436\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.070310\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.144498\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.029335\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.238544\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.021908\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.075308\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.080307\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.075826\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.105793\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.074721\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.068087\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.069961\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.099853\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.146775\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.075723\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.045357\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.093680\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.042875\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.037050\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.088896\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.156315\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.169613\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.131280\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.032521\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.024981\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.155880\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.100213\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.080762\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.100502\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.051968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.137493\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.043665\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.061972\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.139379\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.115079\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.026947\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.016510\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.038457\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.108147\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.202911\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.033911\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.223384\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.105581\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.025809\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.104274\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.088454\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.023274\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.102240\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.050644\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.056152\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.006980\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.124851\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.056049\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.042763\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.126307\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.030691\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.034626\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.125772\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.037375\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.080953\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.060201\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.081346\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.056038\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.088192\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.166253\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.109495\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.064621\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.023071\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.041253\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.180034\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.105325\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.067600\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.022839\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.071439\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.099974\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.089533\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.115353\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.078320\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.031336\n",
      "\n",
      "Test set: Average loss: 0.0632, Accuracy: 9811/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.068113\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.070978\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.032762\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.047030\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.052551\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.076551\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.042349\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.096407\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.148736\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.155266\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.058488\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.024316\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.134536\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.049780\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.096407\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.061939\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.069143\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.112413\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.140715\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.051050\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.221394\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.016814\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.053413\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.088160\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.022856\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.145729\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.083452\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.112112\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.052483\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.103355\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.046819\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.029803\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.018936\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.029664\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.137367\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.039173\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.015575\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.049317\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.016143\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.005910\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.014212\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.023955\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.041113\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.011866\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.074452\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.037520\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.173758\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.124805\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.090640\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.119064\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.133655\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.042365\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.140299\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.028207\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.051544\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.042443\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.063903\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.011643\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.076978\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.095059\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.034043\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.092261\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.146464\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.021753\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.014598\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.050125\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.041441\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.207002\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.019936\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.009628\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.067746\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.029172\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.020827\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.005348\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.029061\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.008053\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.034195\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.020627\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.023224\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.023030\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.030793\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.039532\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.068612\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.034016\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.148836\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.237344\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.212886\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.045240\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.019707\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.132245\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.116599\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.093607\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.138430\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.129925\n",
      "\n",
      "Test set: Average loss: 0.0605, Accuracy: 9807/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.073948\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.079391\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.011793\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.010719\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.020792\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.021148\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.074634\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.030032\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.013758\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.118111\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.060857\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.042249\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.030536\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.010718\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.030861\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.064365\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.019233\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.013233\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.140145\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.128302\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.020616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.102540\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.012186\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.077378\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.040685\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.041111\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.131334\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.125073\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.091454\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.076366\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.029372\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.046609\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.043995\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.096769\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.042039\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.096045\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.104326\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.050276\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.088696\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.065488\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.067313\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.059313\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.069113\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.015422\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.029267\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.044895\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.070051\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.017838\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.094825\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.118784\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.239312\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.016256\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.027887\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.032026\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.080569\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.091191\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.215272\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.076691\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.070621\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.112600\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.047094\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.028970\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.115477\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.203415\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.038564\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.017259\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.045849\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.056289\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.042710\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.093758\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.031610\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.200957\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.008340\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.105628\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.043955\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.025846\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.029271\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.091718\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.029908\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.018885\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.022291\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.037204\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.267645\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.040491\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.020237\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.062033\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.009658\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.045291\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.099761\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.171181\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.102271\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.065363\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.060407\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.040023\n",
      "\n",
      "Test set: Average loss: 0.0570, Accuracy: 9827/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.059521\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.020080\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.026569\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.054520\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.086412\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.035498\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.064067\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.034089\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.102481\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.011871\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.057044\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.037697\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.033220\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.097919\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.041304\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.169727\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.033587\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.025625\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.024283\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.070016\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.027090\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.047437\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.035319\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.048897\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.298674\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.045154\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.030715\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.021407\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.022454\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.013687\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.013871\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.046576\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.033912\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.056811\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.038936\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.016330\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.195044\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.136676\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.075326\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.013719\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.012536\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.054189\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.104924\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.006760\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.043730\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.033477\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.026600\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.029929\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.043853\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.053787\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.040870\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.086994\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.078046\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.059410\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.006784\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.027184\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.019256\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.020247\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.023495\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.030800\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.056291\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.051392\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.047739\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.062263\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.075775\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.026151\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.113412\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.089079\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.079007\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.054039\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.053399\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.116802\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.016810\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.042451\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.029987\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.078590\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.015610\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.018097\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.006880\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.026627\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.020732\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.051403\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.108990\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.139708\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.043346\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.025151\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.041246\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.121819\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.044832\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.017854\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.044073\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.158528\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.153264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.019425\n",
      "\n",
      "Test set: Average loss: 0.0518, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.077649\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.026136\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.142856\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.024593\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.057365\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.038108\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.048627\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.133322\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.053331\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.119194\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.069756\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.006736\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.024762\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.118125\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.009372\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.118075\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.033158\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.061124\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.015065\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.076376\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.196327\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.159469\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.024469\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.120432\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.046150\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.046777\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.093903\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.039540\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.054233\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.016867\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.076698\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.061515\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.131131\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.055935\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.050386\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.015181\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.104980\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.047306\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.008887\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.099642\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.104523\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.028239\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.171939\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.059740\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.057400\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.040061\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.026947\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.033975\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.047811\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.018202\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.032407\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.032600\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.039965\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.137463\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.114804\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.031223\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.012293\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.068881\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.141014\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.040956\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.207481\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.031689\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.056702\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.074375\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.230589\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.011747\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.082778\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.033501\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.071680\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.023483\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.005318\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.061019\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.044450\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.071455\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.070614\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.017523\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.023547\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.068911\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.050336\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.212453\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.030944\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.065178\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.026792\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.020151\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.052509\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.128023\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.025157\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.017641\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.037256\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.073679\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.033158\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.069249\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.095834\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.026988\n",
      "\n",
      "Test set: Average loss: 0.0541, Accuracy: 9816/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
